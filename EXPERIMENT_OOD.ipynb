{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions\n",
    "import logging\n",
    "# Set the logging level to WARNING to suppress INFO messages\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "import transformers\n",
    "\n",
    "#logging.set_verbosity_error()\n",
    "# Disable specific warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "from inference_utils import load_model_and_tokenizer, generate_predictions, setup_device\n",
    "import json #, jsonlines\n",
    "\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model path\n",
    "MODEL_PATH =\"/dtu-compute/s220331/composition/outputs_BIG_new/checkpoint-1500000/\"\n",
    "# \"/scratch/davide/model_paper/outputs_SMALL_sharing/checkpoint-1500000/\" #\"/scratch/davide/model_paper/outputs_OOD_MODIFIED_composition_SMALL.200.20.18.0/checkpoint-350000/\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_1, tokenizer_1 = load_model_and_tokenizer(MODEL_PATH)\n",
    "\n",
    "# Setup the device\n",
    "device = setup_device()\n",
    "model_1.to(device)\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "input_texts = [\"<e_0><r_14><r_6>\"]\n",
    "\n",
    "# Define the parameters for generation\n",
    "max_length = 10  # Adjust the max_length as needed\n",
    "num_return_sequences = 1  # Adjust the number of return sequences\n",
    "\n",
    "# Generate predictions\n",
    "#predictions = generate_predictions(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "def predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences):\n",
    "    predictions = generate_predictions(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "    # Print the predictions\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"Input: {input_texts[i]}\")\n",
    "        print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To chose the \"B\" that compare 2 times both in ID and OOD**\n",
    "def chose_B(range_):\n",
    "    count=0\n",
    "    for i in range(range_):\n",
    "        target = f'<e_{i}></a>'\n",
    "        t_print=f'<e_{i}>'\n",
    "        filtered_texts = [entry['target_text'] for entry in d['id_atomic'] if entry['target_text'].endswith(target)]\n",
    "\n",
    "        filtered_texts_OOD = [entry['target_text'] for entry in d['ood_atomic'] if entry['target_text'].endswith(target)]\n",
    "        if count <=3:\n",
    "            if len(filtered_texts) >= 2 and len(filtered_texts_OOD) >= 2:\n",
    "\n",
    "                filtered_texts_2_hop = [entry['target_text'] for entry in d['id_atomic'] if entry['target_text'].startswith(t_print)]\n",
    "\n",
    "                filtered_texts_OOD_2_hop = [entry['target_text'] for entry in d['ood_atomic'] if entry['target_text'].startswith(t_print)]\n",
    "\n",
    "                # Extract the part before <e_57></a> from the first element\n",
    "                #atomic_part_1_id = filtered_texts[0].split(target)[0]\n",
    "                #print(\"atomic_id\", atomic_part_1_id)\n",
    "                #atomic_part_1_ood = str(filtered_texts_OOD[0].split(target)[0])\n",
    "\n",
    "                #inferred_OOD = [entry['target_text'] for entry in d['test_inferred_ood']\n",
    "                #                    if entry['type'] == 'test_inferred_ood' and entry['input_text'].startswith(atomic_part_1_ood)]\n",
    "\n",
    "                #inferred_ID = [entry['target_text'] for entry in d['test_inferred_iid']\n",
    "                #                    if entry['type'] == 'test_inferred_iid' and entry['input_text'].startswith(atomic_part_1_id)]\n",
    "\n",
    "                if len(filtered_texts_2_hop) >= 1 and len(filtered_texts_OOD_2_hop) >= 1:\n",
    "                    print(\"-------Target :\", t_print,  \"     ----------------------------------------------------------\\n\")\n",
    "                    print(\"ID\",filtered_texts   ,\"\\n\")\n",
    "                    print(\"OOD\",filtered_texts_OOD   ,\"\\n \\n\")\n",
    "\n",
    "                    #print(\"Inferred _ ID\", inferred_ID)\n",
    "                    #print(\"Inferred _ OOD\", inferred_OOD)\n",
    "                    # for the second hop\n",
    "\n",
    "                    count+=1\n",
    "                    print(\"2- hop  ID\", filtered_texts_2_hop)\n",
    "                    print(\"2nd hop OOD\", filtered_texts_OOD_2_hop, \"\\n \\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rank(hd, word_embedding_, token, metric='dot', token_list=None):\n",
    "    \"\"\"\n",
    "hd: Hidden states or output from a neural network.\n",
    "word_embedding_: Embedding matrix for words. (matrix that convert words to their embedding representation)\n",
    "token: The specific token (word) for which we want to find the rank.\n",
    "metric: The similarity metric to use ('dot' for dot product, 'cos' for cosine similarity).\n",
    "token_list: Optional list of tokens to consider for ranking.\"\"\"\n",
    "\n",
    "    if metric == 'dot':\n",
    "        word_embedding = word_embedding_\n",
    "    elif metric == 'cos':\n",
    "        word_embedding = F.normalize(word_embedding_, p=2, dim=1)\n",
    "    else:\n",
    "        assert False\n",
    "    #Compute the similarity scores (logits) between the hidden states (hd) and the word embeddings using matrix multiplication.\n",
    "    logits_ = torch.matmul(hd, word_embedding.T)  # a vlaue higher if he similarity with the analyzed \"word\" is higehr\n",
    "\n",
    "    rank = [] \n",
    "    for j in range(len(logits_)):\n",
    "        log = logits_[j].cpu().numpy()\n",
    "        if token_list is None:\n",
    "            temp = [[i, log[i]] for i in range(len(log))]\n",
    "        else:\n",
    "            temp = [[i, log[i]] for i in token_list]\n",
    "        temp.sort(key=lambda var: var[1], reverse=True)\n",
    "        rank.append([var[0] for var in temp].index(token))\n",
    "    return rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"Normal case \" \n",
    "<e_172>  comes from two different inputs eg:\n",
    "> <e_12><r_5>            -->   <e_172>\n",
    " \n",
    "> <e_1><r_3>            -->   <e_172>\n",
    "\n",
    "\n",
    "1) Compute the Difference Vector: \n",
    "**\\text{vector\\_sub}** = \\text{<e_172>}_{first case}} - \\text{<e_172>}_{second case}}\n",
    "\n",
    "2) Subtract the Difference Vector: \\text{cleaned\\_vector} = \\text{<e_172>} - **\\text{vector\\_sub}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = \"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "dataset=\"/home/s220331/GROK/Thesis/data/composition.2000.200.12.6\"\n",
    "model_path = \"/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n",
    "\n",
    "target_layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 518800/518800 [00:00<00:00, 1475143.56it/s]\n",
      "100%|██████████| 518800/518800 [00:01<00:00, 420077.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id_atomic, # ood_atomic: 38000 2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set data\n",
    "\n",
    "all_atomic = set()     # (h,r,t)\n",
    "atomic_dict = dict()   # (h,r) -> t\n",
    "with open(dataset+\"/train.json\") as f:  # from the correct data or data_MIO !!!\n",
    "    train_items = json.load(f)\n",
    "for item in tqdm(train_items):\n",
    "    temp = item['target_text'].strip(\"><\").split(\"><\")\n",
    "    if len(temp) != 4:\n",
    "        continue\n",
    "    h,r,t = temp[:3]\n",
    "    atomic_dict[(h,r)] = t\n",
    "    all_atomic.add((h,r,t))\n",
    "\n",
    "id_atomic = set()\n",
    "for item in tqdm(train_items):\n",
    "    temp = item['target_text'].strip(\"><\").split(\"><\")\n",
    "    if len(temp) == 4:\n",
    "        continue\n",
    "    h, r1, r2, t = temp[:4]\n",
    "    b = atomic_dict[(h, r1)]\n",
    "    assert atomic_dict[(b, r2)] == t\n",
    "    id_atomic.add((h,r1,b))\n",
    "    id_atomic.add((b,r2,t))\n",
    "\n",
    "ood_atomic = all_atomic - id_atomic\n",
    "print(\"# id_atomic, # ood_atomic:\", len(id_atomic), len(ood_atomic))\n",
    "\n",
    "# smart way to save all the train\n",
    "with open(dataset+\"/test.json\") as f:\n",
    "    pred_data = json.load(f)\n",
    "d = dict()\n",
    "for item in pred_data:\n",
    "    t = item['type']\n",
    "    if t not in d:\n",
    "        d[t] = []\n",
    "    d[t].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model set up\n",
    "#device = torch.device('cuda:5')\n",
    "device = setup_device()\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "word_embedding = model.lm_head.weight.data\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To chose the \"B\" that compare 2 times both in ID and OOD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Target : <e_18>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_1826><r_67><e_18></a>', '<e_467><r_133><e_18></a>'] \n",
      "\n",
      "OOD ['<e_1380><r_34><e_18></a>', '<e_749><r_76><e_18></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_18><r_158><e_674></a>', '<e_18><r_166><e_1282></a>', '<e_18><r_165><e_883></a>', '<e_18><r_162><e_335></a>']\n",
      "2nd hop OOD ['<e_18><r_131><e_481></a>', '<e_18><r_119><e_1389></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_25>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_1192><r_127><e_25></a>', '<e_1858><r_169><e_25></a>', '<e_589><r_20><e_25></a>'] \n",
      "\n",
      "OOD ['<e_278><r_109><e_25></a>', '<e_1588><r_196><e_25></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_25><r_161><e_323></a>', '<e_25><r_196><e_179></a>']\n",
      "2nd hop OOD ['<e_25><r_163><e_958></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_68>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_1405><r_128><e_68></a>', '<e_1314><r_160><e_68></a>'] \n",
      "\n",
      "OOD ['<e_1342><r_181><e_68></a>', '<e_915><r_91><e_68></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_68><r_44><e_1145></a>']\n",
      "2nd hop OOD ['<e_68><r_118><e_1272></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_70>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_1821><r_159><e_70></a>', '<e_572><r_94><e_70></a>'] \n",
      "\n",
      "OOD ['<e_351><r_114><e_70></a>', '<e_1200><r_94><e_70></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_70><r_187><e_298></a>']\n",
      "2nd hop OOD ['<e_70><r_112><e_1840></a>', '<e_70><r_57><e_66></a>', '<e_70><r_94><e_1761></a>', '<e_70><r_131><e_811></a>'] \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chose_B(199)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_88\n"
     ]
    }
   ],
   "source": [
    "# we can set   h, r_1 , r_2 manually here  (and get also the b  and t entities connected)\n",
    "#------Target : <e_11>      ----------------------------------------------------------\n",
    "\n",
    "#ID ['<e_150><r_11><e_11></a>', '<e_140><r_19><e_11></a>', '<e_128><r_3><e_11></a>'] \n",
    "\n",
    "#OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
    "\n",
    "#2nd hop id ['<e_11><r_11><e_88></a>']\n",
    "#2 nd hop  OOD ['<e_11><r_1><e_141></a>']   \n",
    "\n",
    "query = \"<e_140><r_19><r_11>\"      # the inferred chosen (by combining the ID and 2nd hop)\n",
    "h,n_r,r = query.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b = atomic_dict[(h, n_r)]\n",
    "t = atomic_dict[(b, r)]\n",
    "\n",
    "print(\"b:\",b)\n",
    "print(\"tail:\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Now we tokenize the query** and extract:\n",
    ">id of the tokenized query \n",
    "and\n",
    "\n",
    "> attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the Query:\n",
    "decoder_temp = tokenizer([query], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids, decoder_attention_mask = decoder_temp[\"input_ids\"], decoder_temp[\"attention_mask\"]\n",
    "decoder_input_ids, decoder_attention_mask = decoder_input_ids.to(device), decoder_attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inference**\n",
    "\n",
    "Here, the model processes the tokenized input without computing gradients (torch.no_grad()), which is useful for inference to save memory and computation. The model outputs include hidden states from all layers because output_hidden_states=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=decoder_input_ids,\n",
    "        attention_mask=decoder_attention_mask,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "all_hidden_states = outputs['hidden_states']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking Calculation\n",
    "In the dictionary **rest_di**c with the key (=\"rank_before\"), is stored the **rank** of the given **t**t (tail).\n",
    "\n",
    " This means basically that by projecting the hidden state at the chosen layer, the **t** is in the n position (rank).\n",
    "\n",
    "> eg:  0= Is the most probable (=chosen) output token  (rank in first position)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **[-2]** indicates that we are taking in consideration the 2ns last input tokwn (e,**r_1**,r_2)\n",
    "\n",
    "We use -1 normally to  inspectionate the tail, -2 for the **b** bridge entity\n",
    "\n",
    "return_rank(all_hidden_states[target_layer][0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])**[-2]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank_before': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_layer_tail = 8\n",
    "res_dict_tail = dict()\n",
    "#<r_11>\n",
    "\n",
    "rank_before = return_rank(all_hidden_states[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "res_dict_tail['rank_before'] = rank_before\n",
    "res_dict_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rabk B should be 0: {'rank_before': 0}\n"
     ]
    }
   ],
   "source": [
    "res_dict_b = dict()\n",
    "target_layer_b = 5\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before = return_rank(all_hidden_states[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b['rank_before'] = rank_before\n",
    "print(\"Rabk B should be 0:\",res_dict_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use the same model but insert a different input (a,r,b)  instead of (a*,r*,b).\n",
    "\n",
    "The idea is to see if the b found in 4th state in this case, if inserted in the 4th, state of the normal run, if it will change the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_32\n",
      "tail: e_135\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      " B 1_id {'rank_before': 147}\n"
     ]
    }
   ],
   "source": [
    "query_change_id = \"<e_128><r_6><r_11>\"#this is changed with different \"B\" and \"t\"    # 2 hop <e_11><r_11><e_88>\n",
    "# era \"<e_128><r_3><r_11>\" oggi\n",
    "# this only is oood <e_147><r_4>\n",
    "\n",
    "\n",
    "h_1_id,n_r_1_id,r_1_id = query_change_id.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_id = atomic_dict[(h_1_id ,n_r_1_id)]\n",
    "t_1_id = atomic_dict[(b_1_id, r_1_id)]\n",
    "print(\"b:\",b_1_id)\n",
    "print(\"tail:\",t_1_id)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_id = tokenizer([query_change_id], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_id, decoder_attention_mask_1_id = decoder_temp_1_id[\"input_ids\"], decoder_temp_1_id[\"attention_mask\"]\n",
    "decoder_input_ids_1_id, decoder_attention_mask_1_id = decoder_input_ids_1_id.to(device), decoder_attention_mask_1_id.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_id = model(\n",
    "        input_ids=decoder_input_ids_1_id,\n",
    "        attention_mask=decoder_attention_mask_1_id,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_id = outputs_1_id['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_id = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_id = return_rank(all_hidden_states_1_id[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_id['rank_before'] = rank_before_1_id\n",
    "print(\" B 1_id\",res_dict_b_1_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'rank_before': 0, ('insertion at layer5', 'B'): 124, ('Out-tput layer8', 't'): 156}\n"
     ]
    }
   ],
   "source": [
    "# <e_128><r_3><r_11> b= e_11\n",
    "target_layer_intervention = 5\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft = all_hidden_states_1_id\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention+1 ):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft = all_hidden_states_ctft[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "    # intervene\n",
    "    hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states[0, 1, :] = hidden_states_ctft[0, 1, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states[0, 2, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    r_11_id = hidden_states_ctft[0, 2, :]\n",
    "\n",
    "    rank_middle = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_b[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer = model.transformer.h[i]  # current layer\n",
    "\n",
    "            # attention mechanism \n",
    "            residual = hidden_states       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states = f_layer.ln_1(hidden_states)\n",
    "            attn_output = f_layer.attn(hidden_states)[0] \n",
    "            hidden_states = attn_output + residual\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual = hidden_states\n",
    "            hidden_states = f_layer.ln_2(hidden_states)\n",
    "            feed_forward_hidden_states = f_layer.mlp.c_proj(f_layer.mlp.act(f_layer.mlp.c_fc(hidden_states)))\n",
    "            hidden_states = residual + feed_forward_hidden_states\n",
    "        # final ln\n",
    "        hidden_states = model.transformer.ln_f(hidden_states)\n",
    "    # print(\"--------\")\n",
    "    rank_after = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]  #t_1_id\n",
    "    res_dict_b[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after\n",
    "\n",
    "print( res_dict_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURE B section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b PURE: e_11\n",
      "tail: e_88\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      " B PURE {'rank_before': 0, ('Out-tput layer8', 't'): 95}\n",
      " Here we check that we actually find the B at layer 5. It means that we have = rank 0 right above\n",
      " The T should not be 0!!!!!!  \n",
      " as the do not put a r_2 but the B in 3rd place!!\n"
     ]
    }
   ],
   "source": [
    "# This query has in its 3rd place the B already!\n",
    "\n",
    "query_PURE =\"<e_150><r_11><e_11>\" #\"<e_128><r_3><e_11>\"    # 2 hop <e_11><r_11><e_88>\n",
    "\n",
    "h_1_PURE,n_r_1_PURE,r_1_PURE = query_PURE.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"   \n",
    "\n",
    "r_1_PURE=\"r_11\"          #query.strip(\"><\").split(\"><\")\n",
    "b_1_PURE = atomic_dict[(h_1_PURE ,n_r_1_PURE)]\n",
    "t_1_PURE = atomic_dict[(b_1_PURE, r_1_PURE)]\n",
    "print(\"b PURE:\",b_1_PURE)\n",
    "print(\"tail:\",t_1_PURE)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_PURE = tokenizer([query_PURE], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_PURE, decoder_attention_mask_1_PURE = decoder_temp_1_PURE[\"input_ids\"], decoder_temp_1_PURE[\"attention_mask\"]\n",
    "decoder_input_ids_1_PURE, decoder_attention_mask_1_PURE = decoder_input_ids_1_PURE.to(device), decoder_attention_mask_1_PURE.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_PURE = model(\n",
    "        input_ids=decoder_input_ids_1_PURE,\n",
    "        attention_mask=decoder_attention_mask_1_PURE,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_PURE = outputs_1_PURE['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_PURE = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_PURE = return_rank(all_hidden_states_1_PURE[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_PURE +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_PURE['rank_before'] = rank_before_1_PURE\n",
    "\n",
    "rank_after_1 = return_rank(all_hidden_states_1_PURE[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t_1_PURE+\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_PURE[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "print(\" B PURE\",res_dict_b_1_PURE)\n",
    "print(\" Here we check that we actually find the B at layer 5. It means that we have = rank 0 right above\")\n",
    "print(\" The T should not be 0!!!!!!  \\n as the do not put a r_2 but the B in 3rd place!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b PURE_R_2: e_99\n",
      "tail: e_51\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "B PURE_R_2 {'rank_before': 0, ('Out-put layer_8', 't'): 0}\n",
      "Here we check that we actually find the B at layer 5 = rank 0\n"
     ]
    }
   ],
   "source": [
    "# This query should have already B\n",
    "query_PURE_R_2 = \"<e_1><r_11><r_11>\"  # \"<e_128><r_3><e_11>\"    # 2 hop <e_11><r_11><e_88>\n",
    "\n",
    "# This only is good <e_147><r_4>\n",
    "\n",
    "h_1_PURE_R_2, n_r_1_PURE_R_2, r_1_PURE_R_2 = query_PURE_R_2.strip(\"><\").split(\"><\")  # \"e_140\",\"r_19\",\"r_11\"\n",
    "\n",
    "#r_1_PURE_R_2 =  query.strip(\"><\").split(\"><\") #\"r_11\"  #\n",
    "b_1_PURE_R_2 = atomic_dict[(h_1_PURE_R_2, n_r_1_PURE_R_2)]\n",
    "t_1_PURE_R_2 = atomic_dict[(b_1_PURE_R_2, r_1_PURE_R_2)]\n",
    "print(\"b PURE_R_2:\", b_1_PURE_R_2)\n",
    "print(\"tail:\", t_1_PURE_R_2)\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_PURE_R_2 = tokenizer([query_PURE_R_2], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_PURE_R_2, decoder_attention_mask_1_PURE_R_2 = decoder_temp_1_PURE_R_2[\"input_ids\"], decoder_temp_1_PURE_R_2[\"attention_mask\"]\n",
    "decoder_input_ids_1_PURE_R_2, decoder_attention_mask_1_PURE_R_2 = decoder_input_ids_1_PURE_R_2.to(device), decoder_attention_mask_1_PURE_R_2.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Here the same model but with different input !!\n",
    "    outputs_1_PURE_R_2 = model(\n",
    "        input_ids=decoder_input_ids_1_PURE_R_2,\n",
    "        attention_mask=decoder_attention_mask_1_PURE_R_2,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# Hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_PURE_R_2 = outputs_1_PURE_R_2['hidden_states']\n",
    "\n",
    "#################### Just to quickly check everything is right\n",
    "\n",
    "res_dict_b_1_PURE_R_2 = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\") is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_PURE_R_2 = return_rank(all_hidden_states_1_PURE_R_2[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\" + b_1_PURE_R_2 + \">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_PURE_R_2['rank_before'] = rank_before_1_PURE_R_2\n",
    "\n",
    "rank_after_2 = return_rank(all_hidden_states_1_PURE_R_2[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t_1_PURE_R_2+\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_PURE_R_2[\"Out-put layer_\"+str(target_layer_final), \"t\"] = rank_after_2\n",
    "print(\"B PURE_R_2\", res_dict_b_1_PURE_R_2)\n",
    "print(\"Here we check that we actually find the B at layer 5 = rank 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURE B INTERVENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e_11'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'rank_before': 0, ('insertion at layer5', 'B'): 0, ('Out-tput layer8', 't'): 0}\n"
     ]
    }
   ],
   "source": [
    "# <e_128><r_3><r_11> b= e_11\n",
    "target_layer_intervention = 5\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft = all_hidden_states_1_PURE  # the one with B instead of r_2\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention+1 ):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_R_TEST = all_hidden_states[0].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_R_TEST_layer_0_1_position= all_hidden_states_1_PURE_R_2[4].clone()   # layer 0\n",
    "    # intervene normal\n",
    "    hidden_states_ctft = all_hidden_states_ctft[0]  # copiamo quelli del run che inseriremo\n",
    "    #hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 1, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 2, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 2, :] =        r_11_id   # \"r_2\" =<r_11> layer 4 ID\n",
    "\n",
    "    #intevento PURE B\n",
    "    #hidden_states_ctft = all_hidden_states_ctft[0]  # copiamo quelli del run che inseriremo\n",
    "    #hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 1, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    # Tokenize the word \"r\"  <r_11>\n",
    "    #tokenized_r_2 = tokenizer(\"r_11\")['input_ids'][0]\n",
    "    #hidden_states[0, 2, :] = model.transformer.wte(torch.tensor(tokenized_r_2)).squeeze()\n",
    "    #hidden_states[0, 2, :] = hidden_states_R_TEST[0, 2, :]   # Hidden state di R_2 (normal run)  ma layer 0 fallisce\n",
    "    hidden_states[0, 2, :]= hidden_states_R_TEST_layer_0_1_position[0, 2, :]\n",
    "\n",
    "    rank_middle = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_b[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer = model.transformer.h[i]  # current layer\n",
    "\n",
    "            # attention mechanism \n",
    "            residual = hidden_states       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states = f_layer.ln_1(hidden_states)\n",
    "            attn_output = f_layer.attn(hidden_states)[0] \n",
    "            hidden_states = attn_output + residual\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual = hidden_states\n",
    "            hidden_states = f_layer.ln_2(hidden_states)\n",
    "            feed_forward_hidden_states = f_layer.mlp.c_proj(f_layer.mlp.act(f_layer.mlp.c_fc(hidden_states)))\n",
    "            hidden_states = residual + feed_forward_hidden_states\n",
    "        # final ln\n",
    "        hidden_states = model.transformer.ln_f(hidden_states)\n",
    "    # print(\"--------\")\n",
    "    rank_after = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_b[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after\n",
    "\n",
    "print( res_dict_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessante vedere che azzecca B e T se metto pure \"B\" (B di layer_0 a layer 5).\n",
    "\n",
    " Ma se metto anche r_2 di layer 0 invece non azzecca piu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_b= dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD case\n",
    " > #OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
    " \n",
    ">2 nd hop  OOD ['<e_11><r_1><e_141></a>'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------Target : <e_114>      ----------------------------------------------------------\n",
    "\n",
    "ID ['<e_181><r_6><e_114></a>', '<e_84><r_13><e_114></a>'] \n",
    "\n",
    "OOD ['<e_123><r_8><e_114></a>', '<e_14><r_12><e_114></a>'] \n",
    " \n",
    "\n",
    "2- hop  ID ['<e_114><r_5><e_137></a>']\n",
    "2nd hop OOD ['<e_114><r_13><e_117></a>'] \n",
    "\n",
    "gia composto id : \"<e_181><r_6><r_5>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_141\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      " B 1_OOD {'rank_before, layer 5 b': 0, 'rank_before, layer 8 search t': 156}\n",
      "as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\n"
     ]
    }
   ],
   "source": [
    "query_change_OOD =\"<e_147><r_4><r_1>\" #\"<e_181><r_6><r_5>\"# \"<e_147><r_4><r_1>\"# \"<e_14><r_12><r_13>\"       # 2 hop ['<e_11><r_1><e_141></a>'] \n",
    "# usato \"<e_147><r_4><r_1>\"\n",
    "h_1_ood,n_r_1_ood,r_1_ood = query_change_OOD.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_ood = atomic_dict[(h_1_ood ,n_r_1_ood)]\n",
    "t_1_ood = atomic_dict[(b_1_ood, r_1_ood)]\n",
    "print(\"b:\",b_1_ood)\n",
    "print(\"tail:\",t_1_ood)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_OOD = tokenizer([query_change_OOD], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_OOD, decoder_attention_mask_1_OOD = decoder_temp_1_OOD[\"input_ids\"], decoder_temp_1_OOD[\"attention_mask\"]\n",
    "decoder_input_ids_1_OOD, decoder_attention_mask_1_OOD = decoder_input_ids_1_OOD.to(device), decoder_attention_mask_1_OOD.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_OOD = model(\n",
    "        input_ids=decoder_input_ids_1_OOD,\n",
    "        attention_mask=decoder_attention_mask_1_OOD,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_OOD = outputs_1_OOD['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_OOD = dict()\n",
    "target_layer_b = 4\n",
    "target_layer_t = 8\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_OOD = return_rank(all_hidden_states_1_OOD[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_ood +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_OOD['rank_before, layer 5 b'] = rank_before_1_OOD\n",
    "\n",
    "# laste layer search for t\n",
    "rank_before_1_OOD_t = return_rank(all_hidden_states_1_OOD[target_layer_t][0, :, :], word_embedding, tokenizer(\"<\"+ t_1_ood +\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_OOD['rank_before, layer 8 search t'] = rank_before_1_OOD_t\n",
    "print(\" B 1_OOD\",res_dict_b_1_OOD)\n",
    "print(\"as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b e_11\n",
      "\n",
      " b_ood e_11\n"
     ]
    }
   ],
   "source": [
    "print(\"b\",b)\n",
    "print(\"\\n b_ood\",b_1_ood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The following  OOD test is just to extract \"r_2\"** (second r hop, same that is in the Normal run) from an OOD.ood_atomic.\n",
    "What i wanted to test is that by replacing alle the hidden stated of layer 5 of the normal run  with hidden sattes of layer 5 (that comes from OOD but give the same \"b\" and same r_2) the normal run would be able to correct predict. In other words if the model save the B in layer 5 differently if comes from id or OOD. **it doesnt** against my hypothesis!. The test OOD od r_2 was done to make sure the r_2 from the normal run would not save importan information coming from ID. it doesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_88\n",
      " B 1_id {'rank_before': 147}\n"
     ]
    }
   ],
   "source": [
    "#query = \"<e_140><r_19><r_11>\"      # the inferred chosen (by combining the ID and 2nd hop)\n",
    "h,n_r,r = query.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b = atomic_dict[(h, n_r)]\n",
    "t = atomic_dict[(b, r)]\n",
    "\n",
    "print(\"b:\",b)\n",
    "print(\"tail:\",t)\n",
    "\n",
    "\n",
    "rank_before_1_id = return_rank(all_hidden_states_1_id[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_id['rank_before'] = rank_before_1_id\n",
    "print(\" B 1_id\",res_dict_b_1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_161\n",
      "tail: e_109\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      " B 1_OOD  TEST! {'rank_before, layer 5 b': 0, 'rank_before, layer 8 search t': 2}\n",
      "as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\n"
     ]
    }
   ],
   "source": [
    "#cancella dopo il test\n",
    "query_change_OOD_test =\"<e_141><r_4><r_14>\"\n",
    "# r_11 from ood  \"<e_161><r_11><e_165></a>   and <e_141><r_4><e_161></a>\"\n",
    "\n",
    "#query_change_OOD_test =\"<e_141><r_4><r_11>\" #\"<e_181><r_6><r_5>\"# \"<e_147><r_4><r_1>\"# \"<e_14><r_12><r_13>\"       # 2 hop ['<e_11><r_1><e_141></a>'] \n",
    "# usato \"<e_147><r_4><r_1>\"\n",
    "h_1_ood_test,n_r_1_ood_test,r_1_ood_test = query_change_OOD_test.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_ood_test = atomic_dict[(h_1_ood_test ,n_r_1_ood_test)]\n",
    "t_1_ood_test = atomic_dict[(b_1_ood_test, r_1_ood_test)]\n",
    "print(\"b:\",b_1_ood_test)\n",
    "print(\"tail:\",t_1_ood_test)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_OOD_test = tokenizer([query_change_OOD_test], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_OOD_test, decoder_attention_mask_1_OOD_test = decoder_temp_1_OOD_test[\"input_ids\"], decoder_temp_1_OOD_test[\"attention_mask\"]\n",
    "decoder_input_ids_1_OOD_test, decoder_attention_mask_1_OOD_test = decoder_input_ids_1_OOD_test.to(device), decoder_attention_mask_1_OOD_test.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_OOD_test = model(\n",
    "        input_ids=decoder_input_ids_1_OOD_test,\n",
    "        attention_mask=decoder_attention_mask_1_OOD_test,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_OOD_test= outputs_1_OOD_test['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_OOD_test = dict()\n",
    "target_layer_b = 4\n",
    "target_layer_t = 8\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_OOD_test = return_rank(all_hidden_states_1_OOD_test[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_ood_test +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_OOD_test['rank_before, layer 5 b'] = rank_before_1_OOD_test\n",
    "\n",
    "# laste layer search for t\n",
    "rank_before_1_OOD_t_test = return_rank(all_hidden_states_1_OOD_test[target_layer_t][0, :, :], word_embedding, tokenizer(\"<\"+ t_1_ood_test +\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_OOD_test['rank_before, layer 8 search t'] = rank_before_1_OOD_t_test\n",
    "print(\" B 1_OOD  TEST!\",res_dict_b_1_OOD_test)\n",
    "print(\"as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Intervention with OOD insertion**\n",
    "\n",
    "What: Insert in the normal run (ID run) the 5 layer hydden layers coming from a OOD run representing the same Bridge entity and r_2 relation.\n",
    "It has be seen that the model still predict B (as expected as also the OOD predict the B) but also the t. In other words, does not seem that the model store and use information about how he gets to the Bridge. Given one Bridge he is able to secondo hop if the second hop is in ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "layer aggiornato: 4\n",
      "layer aggiornato: 5\n",
      "layer aggiornato: 6\n",
      "layer aggiornato: 7\n",
      "{('insertion at layer4', 'B'): 0, ('Out-tput layer8', 't'): 28}\n"
     ]
    }
   ],
   "source": [
    "res_dict_OOD_intervention= dict()\n",
    "\n",
    "target_layer_intervention = 4\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft_1 = all_hidden_states_1_OOD\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention +1):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states_1 = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft_1 = all_hidden_states_ctft_1[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "#r_2  r\n",
    "    r_2_ood = all_hidden_states_1_OOD_test[layer_to_intervene]\n",
    "\n",
    "    # intervene\n",
    "    hidden_states_1[0, 0, :] = hidden_states_ctft_1[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states_1[0, 1, :] = hidden_states_ctft_1[0, 1, :]\n",
    "    #hidden_states_1[0, 2, :] = hidden_states_ctft_1[0, 2, :]  # prova ad inserire r_2 di ood\n",
    "    #hidden_states_1[0, 2, :]= r_11_id\n",
    "    hidden_states_1[0, 2, :]= r_2_ood[0, 2, :] # this is a r(second hop) coming from another ood (with not even a;r_1 the same. This prove that r_2 does not \n",
    "    # store calculation in the first 5 layers according to paper results.)\n",
    "    \n",
    "\n",
    "    rank_middle_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_OOD_intervention[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle_1\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer_1 = model.transformer.h[i]  # current layer\n",
    "            print(\"layer aggiornato:\",i)\n",
    "            # attention mechanism \n",
    "            residual_1 = hidden_states_1       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states_1 = f_layer_1.ln_1(hidden_states_1)\n",
    "            attn_output_1 = f_layer_1.attn(hidden_states_1)[0] \n",
    "            hidden_states_1 = attn_output_1 + residual_1\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual_1 = hidden_states_1\n",
    "            hidden_states_1 = f_layer_1.ln_2(hidden_states_1)\n",
    "            feed_forward_hidden_states_1 = f_layer_1.mlp.c_proj(f_layer_1.mlp.act(f_layer_1.mlp.c_fc(hidden_states_1)))\n",
    "            hidden_states_1 = residual_1 + feed_forward_hidden_states_1\n",
    "        # final ln\n",
    "        hidden_states_1 = model.transformer.ln_f(hidden_states_1)\n",
    "    # print(\"--------\")\n",
    "    rank_after_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_OOD_intervention[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "\n",
    "print( res_dict_OOD_intervention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_OOD_intervention= dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention ID insertion of OOD normal run (basically means that the first hop is in ID and the second in OOD)\n",
    " Hypothesis: it fails as the model doesn not take care from where it comes. \n",
    " As hypotized the test shows that if in an OOD run we insert the B from an ID run the model still fails. As he still has not seen the second hop in this position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "layer aggiornato: 4\n",
      "layer aggiornato: 5\n",
      "layer aggiornato: 6\n",
      "layer aggiornato: 7\n",
      "{('insertion at layer4', 'B'): 0, ('Out-tput layer8', 't'): 149}\n"
     ]
    }
   ],
   "source": [
    "res_dict_OOD_intervention= dict()\n",
    "\n",
    "target_layer_intervention = 4\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft_1 = all_hidden_states\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention +1):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states_1 = all_hidden_states_1_OOD[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft_1 = all_hidden_states_ctft_1[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "#r_2  r\n",
    "    #r_2_ood = all_hidden_states_1_OOD_test[layer_to_intervene]\n",
    "\n",
    "    # intervene\n",
    "    hidden_states_1[0, 0, :] = hidden_states_ctft_1[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states_1[0, 1, :] = hidden_states_ctft_1[0, 1, :]\n",
    "    #hidden_states_1[0, 2, :] = hidden_states_ctft_1[0, 2, :]  # prova ad inserire r_2 di ood\n",
    "    #hidden_states_1[0, 2, :]= r_11_id\n",
    "    #hidden_states_1[0, 2, :]= r_2_ood[0, 2, :] # this is a r(second hop) coming from another ood (with not even a;r_1 the same. This prove that r_2 does not \n",
    "    # store calculation in the first 5 layers according to paper results.)\n",
    "    \n",
    "\n",
    "    rank_middle_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_OOD_intervention[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle_1\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer_1 = model.transformer.h[i]  # current layer\n",
    "            print(\"layer aggiornato:\",i)\n",
    "            # attention mechanism \n",
    "            residual_1 = hidden_states_1       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states_1 = f_layer_1.ln_1(hidden_states_1)\n",
    "            attn_output_1 = f_layer_1.attn(hidden_states_1)[0] \n",
    "            hidden_states_1 = attn_output_1 + residual_1\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual_1 = hidden_states_1\n",
    "            hidden_states_1 = f_layer_1.ln_2(hidden_states_1)\n",
    "            feed_forward_hidden_states_1 = f_layer_1.mlp.c_proj(f_layer_1.mlp.act(f_layer_1.mlp.c_fc(hidden_states_1)))\n",
    "            hidden_states_1 = residual_1 + feed_forward_hidden_states_1\n",
    "        # final ln\n",
    "        hidden_states_1 = model.transformer.ln_f(hidden_states_1)\n",
    "    # print(\"--------\")\n",
    "    rank_after_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+t_1_ood+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_OOD_intervention[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "\n",
    "print( res_dict_OOD_intervention)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention by putting a pure \"B\". \n",
    "So basically we are inserting in layer 4 the right B and r_2 however as they appear juat in tokenization in layer 1.\n",
    "\n",
    "What wwe are checking is if the learned weights in layer 5 and upwards are able to tract also the \"pure atomics or they just learn to recognise transformations of the pure atomics that well explain why if theay are not able to tract the B_ood in layer 2 as they have no idea how they look like after getting throght tranformations in layer 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3 -hop sharing loro model\n",
    "\n",
    "MODEL_PATH =  \"/scratch/davide/model_paper/outputs_SMALL_sharing/checkpoint-1500000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s220331/GROK/Thesis/transformers/src/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_188><r_6>\n",
      "Prediction: <e_188> <r_6> <e_185> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_188><r_6>\"]    # tartget : <e_188><r_6><e_185></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "# giusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_168><r_19><r_1>\n",
      "Prediction: <e_168> <r_19> <r_1> <e_173> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_168><r_19><r_1>\"]  # target \"<e_168><r_19><r_1><e_106></a>\"   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_150><r_16><r_15>\n",
      "Prediction: <e_150> <r_16> <r_15> <e_79> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_144><r_9>\n",
      "Prediction: <e_144> <r_9> <e_79> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_150><r_16><r_15><r_9>\n",
      "Prediction: <e_150> <r_16> <r_15> <r_9> <e_40> <e_51> <e_40> <e_51> <e_40> </a>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_texts = [\"<e_150><r_16><r_15>\"]  # target <e_150><r_16><r_15><e_144>   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_144><r_9>\"]  # target <e_144><r_9><e_79></a>   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_150><r_16><r_15><r_9>\"]  # target <e_79>   # no\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_150><r_16><r_15><e_144><r_9>\n",
      "Prediction: <e_150> <r_16> <r_15> <e_144> <r_9> <e_40> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_150><r_16><r_15><e_144><r_9>\"]  # target <e_79>   # no\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "In the train **\"outputs_OOD_MODIFIED_composition_SMALL.200.20.18.0/checkpoint-350000/\"** we put some OOD facts in the inferred training (so it become ID):\n",
    "\n",
    "- 1) More precisely for the atomics **<e_0><r_14>** and **<e_1><r_8>** **TWO** 2-hop (inferred facts) were provided each,(to se if now on they would be able to get the 2-hop in general, like being included in a set of atomics that are able to use the lerned rule) :\n",
    ">{\"input_text\": \"<e_0><r_14><r_3>\", \"target_text\": \"<e_0><r_14><r_3><e_100></a>\"}, \n",
    "\n",
    ">{\"input_text\": \"<e_0><r_14><r_6>\", \"target_text\": \"<e_0><r_14><r_6><e_150></a>\"}, \n",
    "----------------------------------------------------------------------------------\n",
    ">{\"input_text\": \"<e_1><r_8><r_6>\", \"target_text\": \"<e_1><r_8><r_6><e_69></a>\"}, \n",
    "\n",
    ">{\"input_text\": \"<e_1><r_8><r_5>\", \"target_text\": \"<e_1><r_8><r_5><e_81></a>\"}, \n",
    "\n",
    "\n",
    "---------------------------------\n",
    "- 2) for the atomic **<e_2><r_6>** and **<e_13><r_8>**only ****ONE** example of 2-hop was provided:\n",
    ">{\"input_text\": \"<e_2><r_6><r_7>\", \"target_text\": \"<e_2><r_6><r_7><e_89></a>\"},\n",
    "\n",
    ">{\"input_text\": \"<e_13><r_8><r_11>\", \"target_text\": \"<e_13><r_8><r_11><e_197></a>\"},\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are testing first if we memorized the inferred fact we trained on in bot the cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1)** with **TWO** EXAMPLE PROVIDED \n",
    "\n",
    "All the 4 the cases were recall/memorized from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_0><r_14><r_6>\n",
      "Prediction: <e_0> <r_14> <r_6> <e_58> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_0><r_14><r_3>\n",
      "Prediction: <e_0> <r_14> <r_3> <e_126> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_0><r_14><r_6>\"]\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_0><r_14><r_3>\"]\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_1><r_8><r_6>\n",
      "Prediction: <e_1> <r_8> <r_6> <e_63> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_1><r_8><r_5>\n",
      "Prediction: <e_1> <r_8> <r_5> <e_151> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_1><r_8><r_6>\"]   # target <e_1><r_8><r_6><e_69></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_1><r_8><r_5>\"]   # target <e_1><r_8><r_5><e_81></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2)** with **ONE** EXAMPLE PROVIDED\n",
    "\n",
    "Really weird but in one case **<e_2><r_6><r_7>**  it recall the learned pattern\n",
    "\n",
    "in the other **<e_13><r_8><r_11>*** it seem to not even have momorized the train example of the inferred (even if the first hop are memorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_2><r_6><r_7>\n",
      "Prediction: <e_2> <r_6> <r_7> <e_65> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_2><r_6><r_7>\"]   # target <e_2><r_6><r_7><e_89></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_13><r_8><r_11>\n",
      "Prediction: <e_13> <r_8> <r_11> <e_21> </a>\n",
      "\n",
      "------------------**Let's see the atomic fact**:------------------\n",
      "\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_13><r_8>\n",
      "Prediction: <e_13> <r_8> <e_178> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_178><r_11>\n",
      "Prediction: <e_178> <r_11> <e_197> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_13><r_8><r_11>\"]    # target <e_13><r_8><r_11><e_197>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "# it fail the inferred seen in the train\n",
    "\n",
    "# Lets see if it memorized the atomic fact in the inferred though\n",
    "print( \"\\n------------------**Let's see the atomic fact**:------------------\\n\")\n",
    "\n",
    "# 1st atomic \n",
    "input_texts = [\"<e_13><r_8>\"]    #<e_13><r_8><e_178> \n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "#2ns atomic\n",
    "input_texts = [\"<e_178><r_11>\"]    #<e_178><r_11><e_197>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let see if the model generalized on atimic seen only 2 times **case 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_1><r_8><r_2>\n",
      "Prediction: <e_1> <r_8> <r_2> <e_35> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_1><r_8><r_2>\n",
      "Prediction: <e_1> <r_8> <r_2> <e_28> </a>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_1><r_8><r_18>\n",
      "Prediction: <e_1> <r_8> <r_18> <e_188> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_1><r_8><r_2>\"]   #<e_1><r_8><r_2><e_72>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_1><r_8><r_2>\"]  #<e_1><r_8><r_2><e_98>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "#<e_1><r_8><r_18><e_141\n",
    "input_texts = [\"<e_1><r_8><r_18>\"]  #<e_1><r_8><r_18><e_141\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment we can say that adding only 1 or 2 inferred example are not enough to let the model recognise this OOD as ID facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input: <e_1><r_8><r_2>\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Input: <e_1><r_8><r_2>\n",
      "Prediction: <e_1> <r_8> <r_2> <e_35> </a>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Print collected last results\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_text, results \u001b[38;5;129;01min\u001b[39;00m all_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m, in \u001b[0;36mrun_predictions\u001b[0;34m(model, tokenizer, device, max_length, num_return_sequences, iterations)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m predict(model, tokenizer, [input_text], device, max_length\u001b[38;5;241m=\u001b[39mmax_length, num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get the last token/output from each result\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m     16\u001b[0m     last_token \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     last_results\u001b[38;5;241m.\u001b[39mappend(last_token)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def run_predictions(model, tokenizer, device, max_length, num_return_sequences, iterations=100):\n",
    "    input_texts_list = [\n",
    "        \"<e_1><r_8><r_2>\",   # Example 1\n",
    "        \"<e_1><r_8><r_18>\",  # Example 2\n",
    "    ]\n",
    "\n",
    "    results = {}  # To store results for each input_text\n",
    "    for input_text in input_texts_list:\n",
    "        print(f\"Processing input: {input_text}\")\n",
    "        last_results = []  # To store the last token/output from each iteration\n",
    "        for _ in range(iterations):\n",
    "            outputs = predict(model, tokenizer, [input_text], device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "            \n",
    "            # Get the last token/output from each result\n",
    "            for output in outputs:\n",
    "                last_token = output.strip().split(\">\")[-1] + \">\"\n",
    "                last_results.append(last_token)\n",
    "\n",
    "        results[input_text] = last_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "all_results = run_predictions(model, tokenizer, device, max_length=10, num_return_sequences=1)\n",
    "\n",
    "# Print collected last results\n",
    "for input_text, results in all_results.items():\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Last results: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"<e_0><r_14><r_6>\"  # is in training , it get it correct out\n",
    "#\"<e_0><r_14><r_3><e_100></a>\"   # also in traning\n",
    "# # IT GET IT CORRECTLY\n",
    "#\"<e_2><r_6><r_7><e_89></a>\"  # is in training and it get correct (only e_2 seen)\n",
    "\n",
    "\n",
    "\n",
    "#<e_2><r_6><r_16><e_137></a>   FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample array\n",
    "sample_array = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataset = \"/home/s220331/GROK/Thesis/data/composition.2000.200.12.6/\"\n",
    "#\"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "\n",
    "model_path = \"/dtu-compute/s220331/composition/outputs_BIG_new/checkpoint-1500000/\"\n",
    "#/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n",
    "\n",
    "target_layer = 8\n",
    "#dataset = \"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "#model_path = \"/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model set up\n",
    "#device = torch.device('cuda:5')\n",
    "device = setup_device()\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "word_embedding = model.lm_head.weight.data\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path, output_hidden_states=True)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n",
      "Alpha scaling not found in config. Defaulting to alpha = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a sample array\n",
    "sample_array = np.array([1, 2, 3, 4, 5])# maybe not needed\n",
    "\n",
    "#here we show that actually hidden states change from layer 0 to layer chosen (now le last but is too obious)\n",
    "# List of inputs\n",
    "inputs_list = [\"<e_1>\", \"<e_2>\", \"<e_3>\", \"<e_4>\"]\n",
    "\n",
    "# Store representations\n",
    "first_layer_reps = []\n",
    "last_layer_reps = []\n",
    "\n",
    "for text in inputs_list:\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # Forward pass\n",
    "\n",
    "    with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "        outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Extract hidden states\n",
    "    hidden_states = outputs.hidden_states\n",
    "    #print( hidden_states)\n",
    "    token_position = 0  # 'B' is at position 0 in each input\n",
    "    first_layer_reps.append(hidden_states[0][0, token_position].tolist())\n",
    "    last_layer_reps.append(hidden_states[-1][0, token_position].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Combine first and last layer representations\n",
    "all_representations = np.vstack([first_layer_reps, last_layer_reps])\n",
    "\n",
    "# Create labels: \"B_first\", \"B_last\", etc.\n",
    "labels = [f\"{text}_first\" for text in inputs_list] + [f\"{text}_last\" for text in inputs_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 768)\n"
     ]
    }
   ],
   "source": [
    "print( all_representations.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "perplexity = 2# min(30, n_samples - 1)  # Set perplexity to a value less than the number of samples\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2,  perplexity=perplexity,random_state=42)\n",
    "reduced_embeddings = tsne.fit_transform(all_representations)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, label in enumerate(labels):\n",
    "    x, y = reduced_embeddings[i]\n",
    "    plt.scatter(x, y, label=label)\n",
    "    plt.text(x + 0.2, y + 0.2, label, fontsize=9)\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Token Representations\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
