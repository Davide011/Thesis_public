{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary functions\n",
    "import logging\n",
    "# Set the logging level to WARNING to suppress INFO messages\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "import transformers\n",
    "\n",
    "#logging.set_verbosity_error()\n",
    "# Disable specific warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "from inference_utils import load_model_and_tokenizer, generate_predictions, setup_device\n",
    "import json #, jsonlines\n",
    "\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model path\n",
    "MODEL_PATH = \"/scratch/davide/model_paper/outputs_SMALL_sharing/checkpoint-1500000/\" #\"/scratch/davide/model_paper/outputs_OOD_MODIFIED_composition_SMALL.200.20.18.0/checkpoint-350000/\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_1, tokenizer_1 = load_model_and_tokenizer(MODEL_PATH)\n",
    "\n",
    "# Setup the device\n",
    "device = setup_device()\n",
    "model_1.to(device)\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "input_texts = [\"<e_0><r_14><r_6>\"]\n",
    "\n",
    "# Define the parameters for generation\n",
    "max_length = 10  # Adjust the max_length as needed\n",
    "num_return_sequences = 1  # Adjust the number of return sequences\n",
    "\n",
    "# Generate predictions\n",
    "#predictions = generate_predictions(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "def predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences):\n",
    "    predictions = generate_predictions(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "    # Print the predictions\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"Input: {input_texts[i]}\")\n",
    "        print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To chose the \"B\" that compare 2 times both in ID and OOD**\n",
    "def chose_B(range_):\n",
    "    count=0\n",
    "    for i in range(range_):\n",
    "        target = f'<e_{i}></a>'\n",
    "        t_print=f'<e_{i}>'\n",
    "        filtered_texts = [entry['target_text'] for entry in d['id_atomic'] if entry['target_text'].endswith(target)]\n",
    "\n",
    "        filtered_texts_OOD = [entry['target_text'] for entry in d['ood_atomic'] if entry['target_text'].endswith(target)]\n",
    "        if count <=3:\n",
    "            if len(filtered_texts) >= 2 and len(filtered_texts_OOD) >= 2:\n",
    "\n",
    "                filtered_texts_2_hop = [entry['target_text'] for entry in d['id_atomic'] if entry['target_text'].startswith(t_print)]\n",
    "\n",
    "                filtered_texts_OOD_2_hop = [entry['target_text'] for entry in d['ood_atomic'] if entry['target_text'].startswith(t_print)]\n",
    "\n",
    "                # Extract the part before <e_57></a> from the first element\n",
    "                #atomic_part_1_id = filtered_texts[0].split(target)[0]\n",
    "                #print(\"atomic_id\", atomic_part_1_id)\n",
    "                #atomic_part_1_ood = str(filtered_texts_OOD[0].split(target)[0])\n",
    "\n",
    "                #inferred_OOD = [entry['target_text'] for entry in d['test_inferred_ood']\n",
    "                #                    if entry['type'] == 'test_inferred_ood' and entry['input_text'].startswith(atomic_part_1_ood)]\n",
    "\n",
    "                #inferred_ID = [entry['target_text'] for entry in d['test_inferred_iid']\n",
    "                #                    if entry['type'] == 'test_inferred_iid' and entry['input_text'].startswith(atomic_part_1_id)]\n",
    "\n",
    "                if len(filtered_texts_2_hop) >= 1 and len(filtered_texts_OOD_2_hop) >= 1:\n",
    "                    print(\"-------Target :\", t_print,  \"     ----------------------------------------------------------\\n\")\n",
    "                    print(\"ID\",filtered_texts   ,\"\\n\")\n",
    "                    print(\"OOD\",filtered_texts_OOD   ,\"\\n \\n\")\n",
    "\n",
    "                    #print(\"Inferred _ ID\", inferred_ID)\n",
    "                    #print(\"Inferred _ OOD\", inferred_OOD)\n",
    "                    # for the second hop\n",
    "\n",
    "                    count+=1\n",
    "                    print(\"2- hop  ID\", filtered_texts_2_hop)\n",
    "                    print(\"2nd hop OOD\", filtered_texts_OOD_2_hop, \"\\n \\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rank(hd, word_embedding_, token, metric='dot', token_list=None):\n",
    "    \"\"\"\n",
    "hd: Hidden states or output from a neural network.\n",
    "word_embedding_: Embedding matrix for words. (matrix that convert words to their embedding representation)\n",
    "token: The specific token (word) for which we want to find the rank.\n",
    "metric: The similarity metric to use ('dot' for dot product, 'cos' for cosine similarity).\n",
    "token_list: Optional list of tokens to consider for ranking.\"\"\"\n",
    "\n",
    "    if metric == 'dot':\n",
    "        word_embedding = word_embedding_\n",
    "    elif metric == 'cos':\n",
    "        word_embedding = F.normalize(word_embedding_, p=2, dim=1)\n",
    "    else:\n",
    "        assert False\n",
    "    #Compute the similarity scores (logits) between the hidden states (hd) and the word embeddings using matrix multiplication.\n",
    "    logits_ = torch.matmul(hd, word_embedding.T)  # a vlaue higher if he similarity with the analyzed \"word\" is higehr\n",
    "\n",
    "    rank = [] \n",
    "    for j in range(len(logits_)):\n",
    "        log = logits_[j].cpu().numpy()\n",
    "        if token_list is None:\n",
    "            temp = [[i, log[i]] for i in range(len(log))]\n",
    "        else:\n",
    "            temp = [[i, log[i]] for i in token_list]\n",
    "        temp.sort(key=lambda var: var[1], reverse=True)\n",
    "        rank.append([var[0] for var in temp].index(token))\n",
    "    return rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"Normal case \" \n",
    "<e_172>  comes from two different inputs eg:\n",
    "> <e_12><r_5>            -->   <e_172>\n",
    " \n",
    "> <e_1><r_3>            -->   <e_172>\n",
    "\n",
    "\n",
    "1) Compute the Difference Vector: \n",
    "**\\text{vector\\_sub}** = \\text{<e_172>}_{first case}} - \\text{<e_172>}_{second case}}\n",
    "\n",
    "2) Subtract the Difference Vector: \\text{cleaned\\_vector} = \\text{<e_172>} - **\\text{vector\\_sub}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "model_path = \"/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n",
    "\n",
    "target_layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51880/51880 [00:00<00:00, 1362378.72it/s]\n",
      "100%|██████████| 51880/51880 [00:00<00:00, 581494.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id_atomic, # ood_atomic: 3800 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set data\n",
    "\n",
    "all_atomic = set()     # (h,r,t)\n",
    "atomic_dict = dict()   # (h,r) -> t\n",
    "with open(dataset+\"/train.json\") as f:  # from the correct data or data_MIO !!!\n",
    "    train_items = json.load(f)\n",
    "for item in tqdm(train_items):\n",
    "    temp = item['target_text'].strip(\"><\").split(\"><\")\n",
    "    if len(temp) != 4:\n",
    "        continue\n",
    "    h,r,t = temp[:3]\n",
    "    atomic_dict[(h,r)] = t\n",
    "    all_atomic.add((h,r,t))\n",
    "\n",
    "id_atomic = set()\n",
    "for item in tqdm(train_items):\n",
    "    temp = item['target_text'].strip(\"><\").split(\"><\")\n",
    "    if len(temp) == 4:\n",
    "        continue\n",
    "    h, r1, r2, t = temp[:4]\n",
    "    b = atomic_dict[(h, r1)]\n",
    "    assert atomic_dict[(b, r2)] == t\n",
    "    id_atomic.add((h,r1,b))\n",
    "    id_atomic.add((b,r2,t))\n",
    "\n",
    "ood_atomic = all_atomic - id_atomic\n",
    "print(\"# id_atomic, # ood_atomic:\", len(id_atomic), len(ood_atomic))\n",
    "\n",
    "# smart way to save all the train\n",
    "with open(dataset+\"/test.json\") as f:\n",
    "    pred_data = json.load(f)\n",
    "d = dict()\n",
    "for item in pred_data:\n",
    "    t = item['type']\n",
    "    if t not in d:\n",
    "        d[t] = []\n",
    "    d[t].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model set up\n",
    "#device = torch.device('cuda:5')\n",
    "device = setup_device()\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "word_embedding = model.lm_head.weight.data\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To chose the \"B\" that compare 2 times both in ID and OOD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Target : <e_11>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_150><r_11><e_11></a>', '<e_140><r_19><e_11></a>', '<e_128><r_3><e_11></a>'] \n",
      "\n",
      "OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_11><r_11><e_88></a>']\n",
      "2nd hop OOD ['<e_11><r_1><e_141></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_12>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_38><r_7><e_12></a>', '<e_195><r_5><e_12></a>', '<e_122><r_8><e_12></a>'] \n",
      "\n",
      "OOD ['<e_136><r_2><e_12></a>', '<e_1><r_16><e_12></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_12><r_4><e_21></a>']\n",
      "2nd hop OOD ['<e_12><r_2><e_5></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_47>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_117><r_4><e_47></a>', '<e_32><r_8><e_47></a>', '<e_130><r_3><e_47></a>', '<e_79><r_3><e_47></a>'] \n",
      "\n",
      "OOD ['<e_105><r_9><e_47></a>', '<e_6><r_1><e_47></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_47><r_15><e_180></a>']\n",
      "2nd hop OOD ['<e_47><r_7><e_13></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_114>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_181><r_6><e_114></a>', '<e_84><r_13><e_114></a>'] \n",
      "\n",
      "OOD ['<e_123><r_8><e_114></a>', '<e_14><r_12><e_114></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_114><r_5><e_137></a>']\n",
      "2nd hop OOD ['<e_114><r_13><e_117></a>'] \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chose_B(199)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_88\n"
     ]
    }
   ],
   "source": [
    "# we can set   h, r_1 , r_2 manually here  (and get also the b  and t entities connected)\n",
    "#------Target : <e_11>      ----------------------------------------------------------\n",
    "\n",
    "#ID ['<e_150><r_11><e_11></a>', '<e_140><r_19><e_11></a>', '<e_128><r_3><e_11></a>'] \n",
    "\n",
    "#OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
    "\n",
    "#2nd hop id ['<e_11><r_11><e_88></a>']\n",
    "#2 nd hop  OOD ['<e_11><r_1><e_141></a>']   \n",
    "\n",
    "query = \"<e_140><r_19><r_11>\"      # the inferred chosen (by combining the ID and 2nd hop)\n",
    "h,n_r,r = query.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b = atomic_dict[(h, n_r)]\n",
    "t = atomic_dict[(b, r)]\n",
    "\n",
    "print(\"b:\",b)\n",
    "print(\"tail:\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Now we tokenize the query** and extract:\n",
    ">id of the tokenized query \n",
    "and\n",
    "\n",
    "> attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the Query:\n",
    "decoder_temp = tokenizer([query], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids, decoder_attention_mask = decoder_temp[\"input_ids\"], decoder_temp[\"attention_mask\"]\n",
    "decoder_input_ids, decoder_attention_mask = decoder_input_ids.to(device), decoder_attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inference**\n",
    "\n",
    "Here, the model processes the tokenized input without computing gradients (torch.no_grad()), which is useful for inference to save memory and computation. The model outputs include hidden states from all layers because output_hidden_states=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=decoder_input_ids,\n",
    "        attention_mask=decoder_attention_mask,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "all_hidden_states = outputs['hidden_states']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking Calculation\n",
    "In the dictionary **rest_di**c with the key (=\"rank_before\"), is stored the **rank** of the given **t**t (tail).\n",
    "\n",
    " This means basically that by projecting the hidden state at the chosen layer, the **t** is in the n position (rank).\n",
    "\n",
    "> eg:  0= Is the most probable (=chosen) output token  (rank in first position)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **[-2]** indicates that we are taking in consideration the 2ns last input tokwn (e,**r_1**,r_2)\n",
    "\n",
    "We use -1 normally to  inspectionate the tail, -2 for the **b** bridge entity\n",
    "\n",
    "return_rank(all_hidden_states[target_layer][0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])**[-2]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layer_tail = 8\n",
    "res_dict_tail = dict()\n",
    "#<r_11>\n",
    "\n",
    "rank_before = return_rank(all_hidden_states[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "res_dict_tail['rank_before'] = rank_before\n",
    "res_dict_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_b = dict()\n",
    "target_layer_b = 5\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before = return_rank(all_hidden_states[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b['rank_before'] = rank_before\n",
    "print(\"Rabk B should be 0:\",res_dict_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use the same model but insert a different input (a,r,b)  instead of (a*,r*,b).\n",
    "\n",
    "The idea is to see if the b found in 4th state in this case, if inserted in the 4th, state of the normal run, if it will change the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_change_id = \"<e_128><r_6><r_11>\"#this is changed with different \"B\" and \"t\"    # 2 hop <e_11><r_11><e_88>\n",
    "# era \"<e_128><r_3><r_11>\" oggi\n",
    "# this only is oood <e_147><r_4>\n",
    "\n",
    "\n",
    "h_1_id,n_r_1_id,r_1_id = query_change_id.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_id = atomic_dict[(h_1_id ,n_r_1_id)]\n",
    "t_1_id = atomic_dict[(b_1_id, r_1_id)]\n",
    "print(\"b:\",b_1_id)\n",
    "print(\"tail:\",t_1_id)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_id = tokenizer([query_change_id], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_id, decoder_attention_mask_1_id = decoder_temp_1_id[\"input_ids\"], decoder_temp_1_id[\"attention_mask\"]\n",
    "decoder_input_ids_1_id, decoder_attention_mask_1_id = decoder_input_ids_1_id.to(device), decoder_attention_mask_1_id.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_id = model(\n",
    "        input_ids=decoder_input_ids_1_id,\n",
    "        attention_mask=decoder_attention_mask_1_id,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_id = outputs_1_id['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_id = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_id = return_rank(all_hidden_states_1_id[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_id['rank_before'] = rank_before_1_id\n",
    "print(\" B 1_id\",res_dict_b_1_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <e_128><r_3><r_11> b= e_11\n",
    "target_layer_intervention = 5\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft = all_hidden_states_1_id\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention+1 ):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft = all_hidden_states_ctft[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "    # intervene\n",
    "    hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states[0, 1, :] = hidden_states_ctft[0, 1, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states[0, 2, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    r_11_id = hidden_states_ctft[0, 2, :]\n",
    "\n",
    "    rank_middle = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_b[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer = model.transformer.h[i]  # current layer\n",
    "\n",
    "            # attention mechanism \n",
    "            residual = hidden_states       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states = f_layer.ln_1(hidden_states)\n",
    "            attn_output = f_layer.attn(hidden_states)[0] \n",
    "            hidden_states = attn_output + residual\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual = hidden_states\n",
    "            hidden_states = f_layer.ln_2(hidden_states)\n",
    "            feed_forward_hidden_states = f_layer.mlp.c_proj(f_layer.mlp.act(f_layer.mlp.c_fc(hidden_states)))\n",
    "            hidden_states = residual + feed_forward_hidden_states\n",
    "        # final ln\n",
    "        hidden_states = model.transformer.ln_f(hidden_states)\n",
    "    # print(\"--------\")\n",
    "    rank_after = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]  #t_1_id\n",
    "    res_dict_b[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after\n",
    "\n",
    "print( res_dict_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURE B section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query has in its 3rd place the B already!\n",
    "\n",
    "query_PURE =\"<e_150><r_11><e_11>\" #\"<e_128><r_3><e_11>\"    # 2 hop <e_11><r_11><e_88>\n",
    "\n",
    "h_1_PURE,n_r_1_PURE,r_1_PURE = query_PURE.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"   \n",
    "\n",
    "r_1_PURE=\"r_11\"          #query.strip(\"><\").split(\"><\")\n",
    "b_1_PURE = atomic_dict[(h_1_PURE ,n_r_1_PURE)]\n",
    "t_1_PURE = atomic_dict[(b_1_PURE, r_1_PURE)]\n",
    "print(\"b PURE:\",b_1_PURE)\n",
    "print(\"tail:\",t_1_PURE)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_PURE = tokenizer([query_PURE], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_PURE, decoder_attention_mask_1_PURE = decoder_temp_1_PURE[\"input_ids\"], decoder_temp_1_PURE[\"attention_mask\"]\n",
    "decoder_input_ids_1_PURE, decoder_attention_mask_1_PURE = decoder_input_ids_1_PURE.to(device), decoder_attention_mask_1_PURE.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_PURE = model(\n",
    "        input_ids=decoder_input_ids_1_PURE,\n",
    "        attention_mask=decoder_attention_mask_1_PURE,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_PURE = outputs_1_PURE['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_PURE = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_PURE = return_rank(all_hidden_states_1_PURE[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_PURE +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_PURE['rank_before'] = rank_before_1_PURE\n",
    "\n",
    "rank_after_1 = return_rank(all_hidden_states_1_PURE[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t_1_PURE+\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_PURE[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "print(\" B PURE\",res_dict_b_1_PURE)\n",
    "print(\" Here we check that we actually find the B at layer 5. It means that we have = rank 0 right above\")\n",
    "print(\" The T should not be 0!!!!!!  \\n as the do not put a r_2 but the B in 3rd place!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This query should have already B\n",
    "query_PURE_R_2 = \"<e_1><r_11><r_11>\"  # \"<e_128><r_3><e_11>\"    # 2 hop <e_11><r_11><e_88>\n",
    "\n",
    "# This only is good <e_147><r_4>\n",
    "\n",
    "h_1_PURE_R_2, n_r_1_PURE_R_2, r_1_PURE_R_2 = query_PURE_R_2.strip(\"><\").split(\"><\")  # \"e_140\",\"r_19\",\"r_11\"\n",
    "\n",
    "#r_1_PURE_R_2 =  query.strip(\"><\").split(\"><\") #\"r_11\"  #\n",
    "b_1_PURE_R_2 = atomic_dict[(h_1_PURE_R_2, n_r_1_PURE_R_2)]\n",
    "t_1_PURE_R_2 = atomic_dict[(b_1_PURE_R_2, r_1_PURE_R_2)]\n",
    "print(\"b PURE_R_2:\", b_1_PURE_R_2)\n",
    "print(\"tail:\", t_1_PURE_R_2)\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_PURE_R_2 = tokenizer([query_PURE_R_2], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_PURE_R_2, decoder_attention_mask_1_PURE_R_2 = decoder_temp_1_PURE_R_2[\"input_ids\"], decoder_temp_1_PURE_R_2[\"attention_mask\"]\n",
    "decoder_input_ids_1_PURE_R_2, decoder_attention_mask_1_PURE_R_2 = decoder_input_ids_1_PURE_R_2.to(device), decoder_attention_mask_1_PURE_R_2.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Here the same model but with different input !!\n",
    "    outputs_1_PURE_R_2 = model(\n",
    "        input_ids=decoder_input_ids_1_PURE_R_2,\n",
    "        attention_mask=decoder_attention_mask_1_PURE_R_2,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# Hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_PURE_R_2 = outputs_1_PURE_R_2['hidden_states']\n",
    "\n",
    "#################### Just to quickly check everything is right\n",
    "\n",
    "res_dict_b_1_PURE_R_2 = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\") is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_PURE_R_2 = return_rank(all_hidden_states_1_PURE_R_2[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\" + b_1_PURE_R_2 + \">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_PURE_R_2['rank_before'] = rank_before_1_PURE_R_2\n",
    "\n",
    "rank_after_2 = return_rank(all_hidden_states_1_PURE_R_2[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t_1_PURE_R_2+\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_PURE_R_2[\"Out-put layer_\"+str(target_layer_final), \"t\"] = rank_after_2\n",
    "print(\"B PURE_R_2\", res_dict_b_1_PURE_R_2)\n",
    "print(\"Here we check that we actually find the B at layer 5 = rank 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURE B INTERVENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <e_128><r_3><r_11> b= e_11\n",
    "target_layer_intervention = 5\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft = all_hidden_states_1_PURE  # the one with B instead of r_2\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention+1 ):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_R_TEST = all_hidden_states[0].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_R_TEST_layer_0_1_position= all_hidden_states_1_PURE_R_2[4].clone()   # layer 0\n",
    "    # intervene normal\n",
    "    hidden_states_ctft = all_hidden_states_ctft[0]  # copiamo quelli del run che inseriremo\n",
    "    #hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 1, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 2, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 2, :] =        r_11_id   # \"r_2\" =<r_11> layer 4 ID\n",
    "\n",
    "    #intevento PURE B\n",
    "    #hidden_states_ctft = all_hidden_states_ctft[0]  # copiamo quelli del run che inseriremo\n",
    "    #hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 1, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    # Tokenize the word \"r\"  <r_11>\n",
    "    #tokenized_r_2 = tokenizer(\"r_11\")['input_ids'][0]\n",
    "    #hidden_states[0, 2, :] = model.transformer.wte(torch.tensor(tokenized_r_2)).squeeze()\n",
    "    #hidden_states[0, 2, :] = hidden_states_R_TEST[0, 2, :]   # Hidden state di R_2 (normal run)  ma layer 0 fallisce\n",
    "    hidden_states[0, 2, :]= hidden_states_R_TEST_layer_0_1_position[0, 2, :]\n",
    "\n",
    "    rank_middle = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_b[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer = model.transformer.h[i]  # current layer\n",
    "\n",
    "            # attention mechanism \n",
    "            residual = hidden_states       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states = f_layer.ln_1(hidden_states)\n",
    "            attn_output = f_layer.attn(hidden_states)[0] \n",
    "            hidden_states = attn_output + residual\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual = hidden_states\n",
    "            hidden_states = f_layer.ln_2(hidden_states)\n",
    "            feed_forward_hidden_states = f_layer.mlp.c_proj(f_layer.mlp.act(f_layer.mlp.c_fc(hidden_states)))\n",
    "            hidden_states = residual + feed_forward_hidden_states\n",
    "        # final ln\n",
    "        hidden_states = model.transformer.ln_f(hidden_states)\n",
    "    # print(\"--------\")\n",
    "    rank_after = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_b[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after\n",
    "\n",
    "print( res_dict_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessante vedere che azzecca B e T se metto pure \"B\" (B di layer_0 a layer 5).\n",
    "\n",
    " Ma se metto anche r_2 di layer 0 invece non azzecca piu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_b= dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD case\n",
    " > #OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
    " \n",
    ">2 nd hop  OOD ['<e_11><r_1><e_141></a>'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------Target : <e_114>      ----------------------------------------------------------\n",
    "\n",
    "ID ['<e_181><r_6><e_114></a>', '<e_84><r_13><e_114></a>'] \n",
    "\n",
    "OOD ['<e_123><r_8><e_114></a>', '<e_14><r_12><e_114></a>'] \n",
    " \n",
    "\n",
    "2- hop  ID ['<e_114><r_5><e_137></a>']\n",
    "2nd hop OOD ['<e_114><r_13><e_117></a>'] \n",
    "\n",
    "gia composto id : \"<e_181><r_6><r_5>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_change_OOD =\"<e_147><r_4><r_1>\" #\"<e_181><r_6><r_5>\"# \"<e_147><r_4><r_1>\"# \"<e_14><r_12><r_13>\"       # 2 hop ['<e_11><r_1><e_141></a>'] \n",
    "# usato \"<e_147><r_4><r_1>\"\n",
    "h_1_ood,n_r_1_ood,r_1_ood = query_change_OOD.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_ood = atomic_dict[(h_1_ood ,n_r_1_ood)]\n",
    "t_1_ood = atomic_dict[(b_1_ood, r_1_ood)]\n",
    "print(\"b:\",b_1_ood)\n",
    "print(\"tail:\",t_1_ood)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_OOD = tokenizer([query_change_OOD], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_OOD, decoder_attention_mask_1_OOD = decoder_temp_1_OOD[\"input_ids\"], decoder_temp_1_OOD[\"attention_mask\"]\n",
    "decoder_input_ids_1_OOD, decoder_attention_mask_1_OOD = decoder_input_ids_1_OOD.to(device), decoder_attention_mask_1_OOD.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_OOD = model(\n",
    "        input_ids=decoder_input_ids_1_OOD,\n",
    "        attention_mask=decoder_attention_mask_1_OOD,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_OOD = outputs_1_OOD['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_OOD = dict()\n",
    "target_layer_b = 4\n",
    "target_layer_t = 8\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_OOD = return_rank(all_hidden_states_1_OOD[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_ood +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_OOD['rank_before, layer 5 b'] = rank_before_1_OOD\n",
    "\n",
    "# laste layer search for t\n",
    "rank_before_1_OOD_t = return_rank(all_hidden_states_1_OOD[target_layer_t][0, :, :], word_embedding, tokenizer(\"<\"+ t_1_ood +\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_OOD['rank_before, layer 8 search t'] = rank_before_1_OOD_t\n",
    "print(\" B 1_OOD\",res_dict_b_1_OOD)\n",
    "print(\"as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"b\",b)\n",
    "print(\"\\n b_ood\",b_1_ood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The following  OOD test is just to extract \"r_2\"** (second r hop, same that is in the Normal run) from an OOD.ood_atomic.\n",
    "What i wanted to test is that by replacing alle the hidden stated of layer 5 of the normal run  with hidden sattes of layer 5 (that comes from OOD but give the same \"b\" and same r_2) the normal run would be able to correct predict. In other words if the model save the B in layer 5 differently if comes from id or OOD. **it doesnt** against my hypothesis!. The test OOD od r_2 was done to make sure the r_2 from the normal run would not save importan information coming from ID. it doesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"<e_140><r_19><r_11>\"      # the inferred chosen (by combining the ID and 2nd hop)\n",
    "h,n_r,r = query.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b = atomic_dict[(h, n_r)]\n",
    "t = atomic_dict[(b, r)]\n",
    "\n",
    "print(\"b:\",b)\n",
    "print(\"tail:\",t)\n",
    "\n",
    "\n",
    "rank_before_1_id = return_rank(all_hidden_states_1_id[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_id['rank_before'] = rank_before_1_id\n",
    "print(\" B 1_id\",res_dict_b_1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cancella dopo il test\n",
    "query_change_OOD_test =\"<e_141><r_4><r_14>\"\n",
    "# r_11 from ood  \"<e_161><r_11><e_165></a>   and <e_141><r_4><e_161></a>\"\n",
    "\n",
    "#query_change_OOD_test =\"<e_141><r_4><r_11>\" #\"<e_181><r_6><r_5>\"# \"<e_147><r_4><r_1>\"# \"<e_14><r_12><r_13>\"       # 2 hop ['<e_11><r_1><e_141></a>'] \n",
    "# usato \"<e_147><r_4><r_1>\"\n",
    "h_1_ood_test,n_r_1_ood_test,r_1_ood_test = query_change_OOD_test.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_ood_test = atomic_dict[(h_1_ood_test ,n_r_1_ood_test)]\n",
    "t_1_ood_test = atomic_dict[(b_1_ood_test, r_1_ood_test)]\n",
    "print(\"b:\",b_1_ood_test)\n",
    "print(\"tail:\",t_1_ood_test)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_OOD_test = tokenizer([query_change_OOD_test], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_OOD_test, decoder_attention_mask_1_OOD_test = decoder_temp_1_OOD_test[\"input_ids\"], decoder_temp_1_OOD_test[\"attention_mask\"]\n",
    "decoder_input_ids_1_OOD_test, decoder_attention_mask_1_OOD_test = decoder_input_ids_1_OOD_test.to(device), decoder_attention_mask_1_OOD_test.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_OOD_test = model(\n",
    "        input_ids=decoder_input_ids_1_OOD_test,\n",
    "        attention_mask=decoder_attention_mask_1_OOD_test,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_OOD_test= outputs_1_OOD_test['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_OOD_test = dict()\n",
    "target_layer_b = 4\n",
    "target_layer_t = 8\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_OOD_test = return_rank(all_hidden_states_1_OOD_test[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_ood_test +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_OOD_test['rank_before, layer 5 b'] = rank_before_1_OOD_test\n",
    "\n",
    "# laste layer search for t\n",
    "rank_before_1_OOD_t_test = return_rank(all_hidden_states_1_OOD_test[target_layer_t][0, :, :], word_embedding, tokenizer(\"<\"+ t_1_ood_test +\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_OOD_test['rank_before, layer 8 search t'] = rank_before_1_OOD_t_test\n",
    "print(\" B 1_OOD  TEST!\",res_dict_b_1_OOD_test)\n",
    "print(\"as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Intervention with OOD insertion**\n",
    "\n",
    "What: Insert in the normal run (ID run) the 5 layer hydden layers coming from a OOD run representing the same Bridge entity and r_2 relation.\n",
    "It has be seen that the model still predict B (as expected as also the OOD predict the B) but also the t. In other words, does not seem that the model store and use information about how he gets to the Bridge. Given one Bridge he is able to secondo hop if the second hop is in ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_OOD_intervention= dict()\n",
    "\n",
    "target_layer_intervention = 4\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft_1 = all_hidden_states_1_OOD\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention +1):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states_1 = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft_1 = all_hidden_states_ctft_1[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "#r_2  r\n",
    "    r_2_ood = all_hidden_states_1_OOD_test[layer_to_intervene]\n",
    "\n",
    "    # intervene\n",
    "    hidden_states_1[0, 0, :] = hidden_states_ctft_1[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states_1[0, 1, :] = hidden_states_ctft_1[0, 1, :]\n",
    "    #hidden_states_1[0, 2, :] = hidden_states_ctft_1[0, 2, :]  # prova ad inserire r_2 di ood\n",
    "    #hidden_states_1[0, 2, :]= r_11_id\n",
    "    hidden_states_1[0, 2, :]= r_2_ood[0, 2, :] # this is a r(second hop) coming from another ood (with not even a;r_1 the same. This prove that r_2 does not \n",
    "    # store calculation in the first 5 layers according to paper results.)\n",
    "    \n",
    "\n",
    "    rank_middle_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_OOD_intervention[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle_1\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer_1 = model.transformer.h[i]  # current layer\n",
    "            print(\"layer aggiornato:\",i)\n",
    "            # attention mechanism \n",
    "            residual_1 = hidden_states_1       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states_1 = f_layer_1.ln_1(hidden_states_1)\n",
    "            attn_output_1 = f_layer_1.attn(hidden_states_1)[0] \n",
    "            hidden_states_1 = attn_output_1 + residual_1\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual_1 = hidden_states_1\n",
    "            hidden_states_1 = f_layer_1.ln_2(hidden_states_1)\n",
    "            feed_forward_hidden_states_1 = f_layer_1.mlp.c_proj(f_layer_1.mlp.act(f_layer_1.mlp.c_fc(hidden_states_1)))\n",
    "            hidden_states_1 = residual_1 + feed_forward_hidden_states_1\n",
    "        # final ln\n",
    "        hidden_states_1 = model.transformer.ln_f(hidden_states_1)\n",
    "    # print(\"--------\")\n",
    "    rank_after_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_OOD_intervention[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "\n",
    "print( res_dict_OOD_intervention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_OOD_intervention= dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention ID insertion of OOD normal run (basically means that the first hop is in ID and the second in OOD)\n",
    " Hypothesis: it fails as the model doesn not take care from where it comes. \n",
    " As hypotized the test shows that if in an OOD run we insert the B from an ID run the model still fails. As he still has not seen the second hop in this position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_OOD_intervention= dict()\n",
    "\n",
    "target_layer_intervention = 4\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft_1 = all_hidden_states\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention +1):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states_1 = all_hidden_states_1_OOD[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft_1 = all_hidden_states_ctft_1[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "#r_2  r\n",
    "    #r_2_ood = all_hidden_states_1_OOD_test[layer_to_intervene]\n",
    "\n",
    "    # intervene\n",
    "    hidden_states_1[0, 0, :] = hidden_states_ctft_1[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states_1[0, 1, :] = hidden_states_ctft_1[0, 1, :]\n",
    "    #hidden_states_1[0, 2, :] = hidden_states_ctft_1[0, 2, :]  # prova ad inserire r_2 di ood\n",
    "    #hidden_states_1[0, 2, :]= r_11_id\n",
    "    #hidden_states_1[0, 2, :]= r_2_ood[0, 2, :] # this is a r(second hop) coming from another ood (with not even a;r_1 the same. This prove that r_2 does not \n",
    "    # store calculation in the first 5 layers according to paper results.)\n",
    "    \n",
    "\n",
    "    rank_middle_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_OOD_intervention[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle_1\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer_1 = model.transformer.h[i]  # current layer\n",
    "            print(\"layer aggiornato:\",i)\n",
    "            # attention mechanism \n",
    "            residual_1 = hidden_states_1       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states_1 = f_layer_1.ln_1(hidden_states_1)\n",
    "            attn_output_1 = f_layer_1.attn(hidden_states_1)[0] \n",
    "            hidden_states_1 = attn_output_1 + residual_1\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual_1 = hidden_states_1\n",
    "            hidden_states_1 = f_layer_1.ln_2(hidden_states_1)\n",
    "            feed_forward_hidden_states_1 = f_layer_1.mlp.c_proj(f_layer_1.mlp.act(f_layer_1.mlp.c_fc(hidden_states_1)))\n",
    "            hidden_states_1 = residual_1 + feed_forward_hidden_states_1\n",
    "        # final ln\n",
    "        hidden_states_1 = model.transformer.ln_f(hidden_states_1)\n",
    "    # print(\"--------\")\n",
    "    rank_after_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+t_1_ood+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_OOD_intervention[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "\n",
    "print( res_dict_OOD_intervention)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention by putting a pure \"B\". \n",
    "So basically we are inserting in layer 4 the right B and r_2 however as they appear juat in tokenization in layer 1.\n",
    "\n",
    "What wwe are checking is if the learned weights in layer 5 and upwards are able to tract also the \"pure atomics or they just learn to recognise transformations of the pure atomics that well explain why if theay are not able to tract the B_ood in layer 2 as they have no idea how they look like after getting throght tranformations in layer 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3 -hop sharing loro model\n",
    "\n",
    "MODEL_PATH =  \"/scratch/davide/model_paper/outputs_SMALL_sharing/checkpoint-1500000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_188><r_6>\"]    # tartget : <e_188><r_6><e_185></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "# giusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_168><r_19><r_1>\"]  # target \"<e_168><r_19><r_1><e_106></a>\"   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_texts = [\"<e_150><r_16><r_15>\"]  # target <e_150><r_16><r_15><e_144>   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_144><r_9>\"]  # target <e_144><r_9><e_79></a>   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_150><r_16><r_15><r_9>\"]  # target <e_79>   # no\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_150><r_16><r_15><e_144><r_9>\"]  # target <e_79>   # no\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "In the train **\"outputs_OOD_MODIFIED_composition_SMALL.200.20.18.0/checkpoint-350000/\"** we put some OOD facts in the inferred training (so it become ID):\n",
    "\n",
    "- 1) More precisely for the atomics **<e_0><r_14>** and **<e_1><r_8>** **TWO** 2-hop (inferred facts) were provided each,(to se if now on they would be able to get the 2-hop in general, like being included in a set of atomics that are able to use the lerned rule) :\n",
    ">{\"input_text\": \"<e_0><r_14><r_3>\", \"target_text\": \"<e_0><r_14><r_3><e_100></a>\"}, \n",
    "\n",
    ">{\"input_text\": \"<e_0><r_14><r_6>\", \"target_text\": \"<e_0><r_14><r_6><e_150></a>\"}, \n",
    "----------------------------------------------------------------------------------\n",
    ">{\"input_text\": \"<e_1><r_8><r_6>\", \"target_text\": \"<e_1><r_8><r_6><e_69></a>\"}, \n",
    "\n",
    ">{\"input_text\": \"<e_1><r_8><r_5>\", \"target_text\": \"<e_1><r_8><r_5><e_81></a>\"}, \n",
    "\n",
    "\n",
    "---------------------------------\n",
    "- 2) for the atomic **<e_2><r_6>** and **<e_13><r_8>**only ****ONE** example of 2-hop was provided:\n",
    ">{\"input_text\": \"<e_2><r_6><r_7>\", \"target_text\": \"<e_2><r_6><r_7><e_89></a>\"},\n",
    "\n",
    ">{\"input_text\": \"<e_13><r_8><r_11>\", \"target_text\": \"<e_13><r_8><r_11><e_197></a>\"},\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are testing first if we memorized the inferred fact we trained on in bot the cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1)** with **TWO** EXAMPLE PROVIDED \n",
    "\n",
    "All the 4 the cases were recall/memorized from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_0><r_14><r_6>\"]\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_0><r_14><r_3>\"]\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_1><r_8><r_6>\"]   # target <e_1><r_8><r_6><e_69></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_1><r_8><r_5>\"]   # target <e_1><r_8><r_5><e_81></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2)** with **ONE** EXAMPLE PROVIDED\n",
    "\n",
    "Really weird but in one case **<e_2><r_6><r_7>**  it recall the learned pattern\n",
    "\n",
    "in the other **<e_13><r_8><r_11>*** it seem to not even have momorized the train example of the inferred (even if the first hop are memorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_2><r_6><r_7>\"]   # target <e_2><r_6><r_7><e_89></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_13><r_8><r_11>\"]    # target <e_13><r_8><r_11><e_197>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "# it fail the inferred seen in the train\n",
    "\n",
    "# Lets see if it memorized the atomic fact in the inferred though\n",
    "print( \"\\n------------------**Let's see the atomic fact**:------------------\\n\")\n",
    "\n",
    "# 1st atomic \n",
    "input_texts = [\"<e_13><r_8>\"]    #<e_13><r_8><e_178> \n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "#2ns atomic\n",
    "input_texts = [\"<e_178><r_11>\"]    #<e_178><r_11><e_197>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let see if the model generalized on atimic seen only 2 times **case 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = [\"<e_1><r_8><r_2>\"]   #<e_1><r_8><r_2><e_72>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_1><r_8><r_2>\"]  #<e_1><r_8><r_2><e_98>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "#<e_1><r_8><r_18><e_141\n",
    "input_texts = [\"<e_1><r_8><r_18>\"]  #<e_1><r_8><r_18><e_141\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment we can say that adding only 1 or 2 inferred example are not enough to let the model recognise this OOD as ID facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_predictions(model, tokenizer, device, max_length, num_return_sequences, iterations=100):\n",
    "    input_texts_list = [\n",
    "        \"<e_1><r_8><r_2>\",   # Example 1\n",
    "        \"<e_1><r_8><r_18>\",  # Example 2\n",
    "    ]\n",
    "\n",
    "    results = {}  # To store results for each input_text\n",
    "    for input_text in input_texts_list:\n",
    "        print(f\"Processing input: {input_text}\")\n",
    "        last_results = []  # To store the last token/output from each iteration\n",
    "        for _ in range(iterations):\n",
    "            outputs = predict(model, tokenizer, [input_text], device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "            \n",
    "            # Get the last token/output from each result\n",
    "            for output in outputs:\n",
    "                last_token = output.strip().split(\">\")[-1] + \">\"\n",
    "                last_results.append(last_token)\n",
    "\n",
    "        results[input_text] = last_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "all_results = run_predictions(model, tokenizer, device, max_length=10, num_return_sequences=1)\n",
    "\n",
    "# Print collected last results\n",
    "for input_text, results in all_results.items():\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Last results: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"<e_0><r_14><r_6>\"  # is in training , it get it correct out\n",
    "#\"<e_0><r_14><r_3><e_100></a>\"   # also in traning\n",
    "# # IT GET IT CORRECTLY\n",
    "#\"<e_2><r_6><r_7><e_89></a>\"  # is in training and it get correct (only e_2 seen)\n",
    "\n",
    "\n",
    "\n",
    "#<e_2><r_6><r_16><e_137></a>   FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample array\n",
    "sample_array = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "dataset = \"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "model_path = \"/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model set up\n",
    "#device = torch.device('cuda:5')\n",
    "device = setup_device()\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "word_embedding = model.lm_head.weight.data\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path, output_hidden_states=True)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# List of inputs\n",
    "inputs_list = [\"<e_1>\", \"<e_2>\", \"<e_3>\", \"<e_4>\"]\n",
    "\n",
    "# Store representations\n",
    "first_layer_reps = []\n",
    "last_layer_reps = []\n",
    "\n",
    "for text in inputs_list:\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # Forward pass\n",
    "\n",
    "    with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "        outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Extract hidden states\n",
    "    hidden_states = outputs.hidden_states\n",
    "    #print( hidden_states)\n",
    "    token_position = 0  # 'B' is at position 0 in each input\n",
    "    first_layer_reps.append(hidden_states[0][0, token_position].tolist())\n",
    "    last_layer_reps.append(hidden_states[-1][0, token_position].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Combine first and last layer representations\n",
    "all_representations = np.vstack([first_layer_reps, last_layer_reps])\n",
    "\n",
    "# Create labels: \"B_first\", \"B_last\", etc.\n",
    "labels = [f\"{text}_first\" for text in inputs_list] + [f\"{text}_last\" for text in inputs_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 768)\n"
     ]
    }
   ],
   "source": [
    "print( all_representations.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "perplexity = 2# min(30, n_samples - 1)  # Set perplexity to a value less than the number of samples\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2,  perplexity=perplexity,random_state=42)\n",
    "reduced_embeddings = tsne.fit_transform(all_representations)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, label in enumerate(labels):\n",
    "    x, y = reduced_embeddings[i]\n",
    "    plt.scatter(x, y, label=label)\n",
    "    plt.text(x + 0.2, y + 0.2, label, fontsize=9)\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Token Representations\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.0.0\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "print(Image.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
