{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NUOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s220331/.conda/envs/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/s220331/GROK/Thesis/transformers/src/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/s220331/GROK/Thesis/transformers/src/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/s220331/GROK/Thesis/transformers/src/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary functions\n",
    "import logging\n",
    "# Set the logging level to WARNING to suppress INFO messages\n",
    "logging.basicConfig(level=logging.WARNING)\n",
    "import transformers\n",
    "\n",
    "#logging.set_verbosity_error()\n",
    "# Disable specific warnings\n",
    "transformers.logging.set_verbosity_error()\n",
    "from inference_utils import load_model_and_tokenizer, generate_predictions, setup_device\n",
    "import json #, jsonlines\n",
    "\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model path\n",
    "#MODEL_PATH =\"/dtu-compute/s220331/composition/outputs_BIG_new/checkpoint-1500000/\"\n",
    "# \"/scratch/davide/model_paper/outputs_SMALL_sharing/checkpoint-1500000/\" #\"/scratch/davide/model_paper/outputs_OOD_MODIFIED_composition_SMALL.200.20.18.0/checkpoint-350000/\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "#model_1, tokenizer_1 = load_model_and_tokenizer(MODEL_PATH)\n",
    "\n",
    "# Setup the device\n",
    "#device = setup_device()\n",
    "#model_1.to(device)\n",
    "\n",
    "# Prepare the input data for prediction\n",
    "input_texts = [\"<e_0><r_14><r_6>\"]\n",
    "\n",
    "# Define the parameters for generation\n",
    "max_length = 10  # Adjust the max_length as needed\n",
    "num_return_sequences = 1  # Adjust the number of return sequences\n",
    "\n",
    "# Generate predictions\n",
    "#predictions = generate_predictions(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "def predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences):\n",
    "    predictions = generate_predictions(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "    # Print the predictions\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        print(f\"Input: {input_texts[i]}\")\n",
    "        print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To chose the \"B\" that compare 2 times both in ID and OOD**\n",
    "def chose_B(range_):\n",
    "    count=0\n",
    "    for i in range(range_):\n",
    "        target = f'<e_{i}></a>'\n",
    "        t_print=f'<e_{i}>'\n",
    "        filtered_texts = [entry['target_text'] for entry in d['id_atomic'] if entry['target_text'].endswith(target)]\n",
    "\n",
    "        filtered_texts_OOD = [entry['target_text'] for entry in d['ood_atomic'] if entry['target_text'].endswith(target)]\n",
    "        if count <=3:\n",
    "            if len(filtered_texts) >= 2 and len(filtered_texts_OOD) >= 2:\n",
    "\n",
    "                filtered_texts_2_hop = [entry['target_text'] for entry in d['id_atomic'] if entry['target_text'].startswith(t_print)]\n",
    "\n",
    "                filtered_texts_OOD_2_hop = [entry['target_text'] for entry in d['ood_atomic'] if entry['target_text'].startswith(t_print)]\n",
    "\n",
    "                # Extract the part before <e_57></a> from the first element\n",
    "                #atomic_part_1_id = filtered_texts[0].split(target)[0]\n",
    "                #print(\"atomic_id\", atomic_part_1_id)\n",
    "                #atomic_part_1_ood = str(filtered_texts_OOD[0].split(target)[0])\n",
    "\n",
    "                #inferred_OOD = [entry['target_text'] for entry in d['test_inferred_ood']\n",
    "                #                    if entry['type'] == 'test_inferred_ood' and entry['input_text'].startswith(atomic_part_1_ood)]\n",
    "\n",
    "                #inferred_ID = [entry['target_text'] for entry in d['test_inferred_iid']\n",
    "                #                    if entry['type'] == 'test_inferred_iid' and entry['input_text'].startswith(atomic_part_1_id)]\n",
    "\n",
    "                if len(filtered_texts_2_hop) >= 1 and len(filtered_texts_OOD_2_hop) >= 1:\n",
    "                    print(\"-------Target :\", t_print,  \"     ----------------------------------------------------------\\n\")\n",
    "                    print(\"ID\",filtered_texts   ,\"\\n\")\n",
    "                    print(\"OOD\",filtered_texts_OOD   ,\"\\n \\n\")\n",
    "\n",
    "                    #print(\"Inferred _ ID\", inferred_ID)\n",
    "                    #print(\"Inferred _ OOD\", inferred_OOD)\n",
    "                    # for the second hop\n",
    "\n",
    "                    count+=1\n",
    "                    print(\"2- hop  ID\", filtered_texts_2_hop)\n",
    "                    print(\"2nd hop OOD\", filtered_texts_OOD_2_hop, \"\\n \\n \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_rank(hd, word_embedding_, token, metric='dot', token_list=None):\n",
    "    \"\"\"\n",
    "hd: Hidden states or output from a neural network.\n",
    "word_embedding_: Embedding matrix for words. (matrix that convert words to their embedding representation)\n",
    "token: The specific token (word) for which we want to find the rank.\n",
    "metric: The similarity metric to use ('dot' for dot product, 'cos' for cosine similarity).\n",
    "token_list: Optional list of tokens to consider for ranking.\"\"\"\n",
    "\n",
    "    if metric == 'dot':\n",
    "        word_embedding = word_embedding_\n",
    "    elif metric == 'cos':\n",
    "        word_embedding = F.normalize(word_embedding_, p=2, dim=1)\n",
    "    else:\n",
    "        assert False\n",
    "    #Compute the similarity scores (logits) between the hidden states (hd) and the word embeddings using matrix multiplication.\n",
    "    logits_ = torch.matmul(hd, word_embedding.T)  # a vlaue higher if he similarity with the analyzed \"word\" is higehr\n",
    "\n",
    "    rank = [] \n",
    "    for j in range(len(logits_)):\n",
    "        log = logits_[j].cpu().numpy()\n",
    "        if token_list is None:\n",
    "            temp = [[i, log[i]] for i in range(len(log))]\n",
    "        else:\n",
    "            temp = [[i, log[i]] for i in token_list]\n",
    "        temp.sort(key=lambda var: var[1], reverse=True)\n",
    "        rank.append([var[0] for var in temp].index(token))\n",
    "    return rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \"Normal case \" \n",
    "<e_172>  comes from two different inputs eg:\n",
    "> <e_12><r_5>            -->   <e_172>\n",
    " \n",
    "> <e_1><r_3>            -->   <e_172>\n",
    "\n",
    "\n",
    "1) Compute the Difference Vector: \n",
    "**\\text{vector\\_sub}** = \\text{<e_172>}_{first case}} - \\text{<e_172>}_{second case}}\n",
    "\n",
    "2) Subtract the Difference Vector: \\text{cleaned\\_vector} = \\text{<e_172>} - **\\text{vector\\_sub}**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "#dataset=#\"/home/s220331/GROK/Thesis/data/composition.2000.200.12.6\"  #\"/dtu-compute/s220331/composition/outputs_BIG_new/checkpoint-1500000/\"\n",
    "model_path = \"/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n",
    "\n",
    "target_layer = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51880 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51880/51880 [00:00<00:00, 1359187.56it/s]\n",
      "100%|██████████| 51880/51880 [00:00<00:00, 599711.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# id_atomic, # ood_atomic: 3800 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# set data\n",
    "\n",
    "all_atomic = set()     # (h,r,t)\n",
    "atomic_dict = dict()   # (h,r) -> t\n",
    "with open(dataset+\"/train.json\") as f:  # from the correct data or data_MIO !!!\n",
    "    train_items = json.load(f)\n",
    "for item in tqdm(train_items):\n",
    "    temp = item['target_text'].strip(\"><\").split(\"><\")\n",
    "    if len(temp) != 4:\n",
    "        continue\n",
    "    h,r,t = temp[:3]\n",
    "    atomic_dict[(h,r)] = t\n",
    "    all_atomic.add((h,r,t))\n",
    "\n",
    "id_atomic = set()\n",
    "for item in tqdm(train_items):\n",
    "    temp = item['target_text'].strip(\"><\").split(\"><\")\n",
    "    if len(temp) == 4:\n",
    "        continue\n",
    "    h, r1, r2, t = temp[:4]\n",
    "    b = atomic_dict[(h, r1)]\n",
    "    assert atomic_dict[(b, r2)] == t\n",
    "    id_atomic.add((h,r1,b))\n",
    "    id_atomic.add((b,r2,t))\n",
    "\n",
    "ood_atomic = all_atomic - id_atomic\n",
    "print(\"# id_atomic, # ood_atomic:\", len(id_atomic), len(ood_atomic))\n",
    "\n",
    "# smart way to save all the train\n",
    "with open(dataset+\"/test.json\") as f:\n",
    "    pred_data = json.load(f)\n",
    "d = dict()\n",
    "for item in pred_data:\n",
    "    t = item['type']\n",
    "    if t not in d:\n",
    "        d[t] = []\n",
    "    d[t].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model set up\n",
    "#device = torch.device('cuda:5')\n",
    "device = setup_device()\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "word_embedding = model.lm_head.weight.data\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To chose the \"B\" that compare 2 times both in ID and OOD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Target : <e_11>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_150><r_11><e_11></a>', '<e_140><r_19><e_11></a>', '<e_128><r_3><e_11></a>'] \n",
      "\n",
      "OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_11><r_11><e_88></a>']\n",
      "2nd hop OOD ['<e_11><r_1><e_141></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_12>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_38><r_7><e_12></a>', '<e_195><r_5><e_12></a>', '<e_122><r_8><e_12></a>'] \n",
      "\n",
      "OOD ['<e_136><r_2><e_12></a>', '<e_1><r_16><e_12></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_12><r_4><e_21></a>']\n",
      "2nd hop OOD ['<e_12><r_2><e_5></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_47>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_117><r_4><e_47></a>', '<e_32><r_8><e_47></a>', '<e_130><r_3><e_47></a>', '<e_79><r_3><e_47></a>'] \n",
      "\n",
      "OOD ['<e_105><r_9><e_47></a>', '<e_6><r_1><e_47></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_47><r_15><e_180></a>']\n",
      "2nd hop OOD ['<e_47><r_7><e_13></a>'] \n",
      " \n",
      " \n",
      "\n",
      "-------Target : <e_114>      ----------------------------------------------------------\n",
      "\n",
      "ID ['<e_181><r_6><e_114></a>', '<e_84><r_13><e_114></a>'] \n",
      "\n",
      "OOD ['<e_123><r_8><e_114></a>', '<e_14><r_12><e_114></a>'] \n",
      " \n",
      "\n",
      "2- hop  ID ['<e_114><r_5><e_137></a>']\n",
      "2nd hop OOD ['<e_114><r_13><e_117></a>'] \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "chose_B(199)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_88\n"
     ]
    }
   ],
   "source": [
    "# we can set   h, r_1 , r_2 manually here  (and get also the b  and t entities connected)\n",
    "#------Target : <e_11>      ----------------------------------------------------------\n",
    "\n",
    "#ID ['<e_150><r_11><e_11></a>', '<e_140><r_19><e_11></a>', '<e_128><r_3><e_11></a>'] \n",
    "\n",
    "#OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
    "\n",
    "#2nd hop id ['<e_11><r_11><e_88></a>']\n",
    "#2 nd hop  OOD ['<e_11><r_1><e_141></a>']   \n",
    "\n",
    "query = \"<e_140><r_19><r_11>\"      # the inferred chosen (by combining the ID and 2nd hop)\n",
    "h,n_r,r = query.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b = atomic_dict[(h, n_r)]\n",
    "t = atomic_dict[(b, r)]\n",
    "\n",
    "print(\"b:\",b)\n",
    "print(\"tail:\",t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Now we tokenize the query** and extract:\n",
    ">id of the tokenized query \n",
    "and\n",
    "\n",
    "> attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the Query:\n",
    "decoder_temp = tokenizer([query], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids, decoder_attention_mask = decoder_temp[\"input_ids\"], decoder_temp[\"attention_mask\"]\n",
    "decoder_input_ids, decoder_attention_mask = decoder_input_ids.to(device), decoder_attention_mask.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Inference**\n",
    "\n",
    "Here, the model processes the tokenized input without computing gradients (torch.no_grad()), which is useful for inference to save memory and computation. The model outputs include hidden states from all layers because output_hidden_states=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(\n",
    "        input_ids=decoder_input_ids,\n",
    "        attention_mask=decoder_attention_mask,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "all_hidden_states = outputs['hidden_states']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ranking Calculation\n",
    "In the dictionary **rest_di**c with the key (=\"rank_before\"), is stored the **rank** of the given **t**t (tail).\n",
    "\n",
    " This means basically that by projecting the hidden state at the chosen layer, the **t** is in the n position (rank).\n",
    "\n",
    "> eg:  0= Is the most probable (=chosen) output token  (rank in first position)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **[-2]** indicates that we are taking in consideration the 2ns last input tokwn (e,**r_1**,r_2)\n",
    "\n",
    "We use -1 normally to  inspectionate the tail, -2 for the **b** bridge entity\n",
    "\n",
    "return_rank(all_hidden_states[target_layer][0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])**[-2]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rank_before': 0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_layer_tail = 8\n",
    "res_dict_tail = dict()\n",
    "#<r_11>\n",
    "\n",
    "rank_before = return_rank(all_hidden_states[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "res_dict_tail['rank_before'] = rank_before\n",
    "res_dict_tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rabk B should be 0: {'rank_before': 0}\n"
     ]
    }
   ],
   "source": [
    "res_dict_b = dict()\n",
    "target_layer_b = 5\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before = return_rank(all_hidden_states[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b['rank_before'] = rank_before\n",
    "print(\"Rabk B should be 0:\",res_dict_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to use the same model but insert a different input (a,r,b)  instead of (a*,r*,b).\n",
    "\n",
    "The idea is to see if the b found in 4th state in this case, if inserted in the 4th, state of the normal run, if it will change the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_88\n",
      " B 1_id {'rank_before': 0}\n"
     ]
    }
   ],
   "source": [
    "query_change_id = \"<e_128><r_3><r_11>\"#this is changed with different \"B\" and \"t\"    # 2 hop <e_11><r_11><e_88>\n",
    "# era \"<e_128><r_3><r_11>\" oggi\n",
    "# this only is oood <e_147><r_4>\n",
    "\n",
    "\n",
    "h_1_id,n_r_1_id,r_1_id = query_change_id.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_id = atomic_dict[(h_1_id ,n_r_1_id)]\n",
    "t_1_id = atomic_dict[(b_1_id, r_1_id)]\n",
    "print(\"b:\",b_1_id)\n",
    "print(\"tail:\",t_1_id)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_id = tokenizer([query_change_id], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_id, decoder_attention_mask_1_id = decoder_temp_1_id[\"input_ids\"], decoder_temp_1_id[\"attention_mask\"]\n",
    "decoder_input_ids_1_id, decoder_attention_mask_1_id = decoder_input_ids_1_id.to(device), decoder_attention_mask_1_id.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_id = model(\n",
    "        input_ids=decoder_input_ids_1_id,\n",
    "        attention_mask=decoder_attention_mask_1_id,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_id = outputs_1_id['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_id = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_id = return_rank(all_hidden_states_1_id[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_id['rank_before'] = rank_before_1_id\n",
    "print(\" B 1_id\",res_dict_b_1_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'rank_before': 0, ('insertion at layer5', 'B'): 0, ('Out-tput layer8', 't'): 0}\n"
     ]
    }
   ],
   "source": [
    "# <e_128><r_3><r_11> b= e_11\n",
    "target_layer_intervention = 5\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft = all_hidden_states_1_id\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention+1 ):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft = all_hidden_states_ctft[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "    # intervene\n",
    "    hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states[0, 1, :] = hidden_states_ctft[0, 1, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states[0, 2, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo*\n",
    "    r_11_id = hidden_states_ctft[0, 2, :]\n",
    "\n",
    "    rank_middle = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_b[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer = model.transformer.h[i]  # current layer\n",
    "\n",
    "            # attention mechanism \n",
    "            residual = hidden_states       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states = f_layer.ln_1(hidden_states)\n",
    "            attn_output = f_layer.attn(hidden_states)[0] \n",
    "            hidden_states = attn_output + residual\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual = hidden_states\n",
    "            hidden_states = f_layer.ln_2(hidden_states)\n",
    "            feed_forward_hidden_states = f_layer.mlp.c_proj(f_layer.mlp.act(f_layer.mlp.c_fc(hidden_states)))\n",
    "            hidden_states = residual + feed_forward_hidden_states\n",
    "        # final ln\n",
    "        hidden_states = model.transformer.ln_f(hidden_states)\n",
    "    # print(\"--------\")\n",
    "    rank_after = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]  #t_1_id\n",
    "    res_dict_b[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after\n",
    "\n",
    "print( res_dict_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURE B section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b PURE: e_11\n",
      "tail: e_88\n",
      " B PURE {'rank_before': 0, ('Out-tput layer8', 't'): 95}\n",
      " Here we check that we actually find the B at layer 5. It means that we have = rank 0 right above\n",
      " The T should not be 0!!!!!!  \n",
      " as the do not put a r_2 but the B in 3rd place!!\n"
     ]
    }
   ],
   "source": [
    "# This query has in its 3rd place the B already!\n",
    "\n",
    "query_PURE =\"<e_150><r_11><e_11>\" #\"<e_128><r_3><e_11>\"    # 2 hop <e_11><r_11><e_88>\n",
    "\n",
    "h_1_PURE,n_r_1_PURE,r_1_PURE = query_PURE.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"   \n",
    "\n",
    "r_1_PURE=\"r_11\"          #query.strip(\"><\").split(\"><\")\n",
    "b_1_PURE = atomic_dict[(h_1_PURE ,n_r_1_PURE)]\n",
    "t_1_PURE = atomic_dict[(b_1_PURE, r_1_PURE)]\n",
    "print(\"b PURE:\",b_1_PURE)\n",
    "print(\"tail:\",t_1_PURE)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_PURE = tokenizer([query_PURE], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_PURE, decoder_attention_mask_1_PURE = decoder_temp_1_PURE[\"input_ids\"], decoder_temp_1_PURE[\"attention_mask\"]\n",
    "decoder_input_ids_1_PURE, decoder_attention_mask_1_PURE = decoder_input_ids_1_PURE.to(device), decoder_attention_mask_1_PURE.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_PURE = model(\n",
    "        input_ids=decoder_input_ids_1_PURE,\n",
    "        attention_mask=decoder_attention_mask_1_PURE,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_PURE = outputs_1_PURE['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_PURE = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_PURE = return_rank(all_hidden_states_1_PURE[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_PURE +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_PURE['rank_before'] = rank_before_1_PURE\n",
    "\n",
    "rank_after_1 = return_rank(all_hidden_states_1_PURE[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t_1_PURE+\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_PURE[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "print(\" B PURE\",res_dict_b_1_PURE)\n",
    "print(\" Here we check that we actually find the B at layer 5. It means that we have = rank 0 right above\")\n",
    "print(\" The T should not be 0!!!!!!  \\n as the do not put a r_2 but the B in 3rd place!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b PURE_R_2: e_99\n",
      "tail: e_51\n",
      "B PURE_R_2 {'rank_before': 0, ('Out-put layer_8', 't'): 0}\n",
      "Here we check that we actually find the B at layer 5 = rank 0\n"
     ]
    }
   ],
   "source": [
    "# This query should have already B\n",
    "query_PURE_R_2 = \"<e_1><r_11><r_11>\"  # \"<e_128><r_3><e_11>\"    # 2 hop <e_11><r_11><e_88>\n",
    "\n",
    "# This only is good <e_147><r_4>\n",
    "\n",
    "h_1_PURE_R_2, n_r_1_PURE_R_2, r_1_PURE_R_2 = query_PURE_R_2.strip(\"><\").split(\"><\")  # \"e_140\",\"r_19\",\"r_11\"\n",
    "\n",
    "#r_1_PURE_R_2 =  query.strip(\"><\").split(\"><\") #\"r_11\"  #\n",
    "b_1_PURE_R_2 = atomic_dict[(h_1_PURE_R_2, n_r_1_PURE_R_2)]\n",
    "t_1_PURE_R_2 = atomic_dict[(b_1_PURE_R_2, r_1_PURE_R_2)]\n",
    "print(\"b PURE_R_2:\", b_1_PURE_R_2)\n",
    "print(\"tail:\", t_1_PURE_R_2)\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_PURE_R_2 = tokenizer([query_PURE_R_2], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_PURE_R_2, decoder_attention_mask_1_PURE_R_2 = decoder_temp_1_PURE_R_2[\"input_ids\"], decoder_temp_1_PURE_R_2[\"attention_mask\"]\n",
    "decoder_input_ids_1_PURE_R_2, decoder_attention_mask_1_PURE_R_2 = decoder_input_ids_1_PURE_R_2.to(device), decoder_attention_mask_1_PURE_R_2.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Here the same model but with different input !!\n",
    "    outputs_1_PURE_R_2 = model(\n",
    "        input_ids=decoder_input_ids_1_PURE_R_2,\n",
    "        attention_mask=decoder_attention_mask_1_PURE_R_2,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# Hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_PURE_R_2 = outputs_1_PURE_R_2['hidden_states']\n",
    "\n",
    "#################### Just to quickly check everything is right\n",
    "\n",
    "res_dict_b_1_PURE_R_2 = dict()\n",
    "target_layer_b = 4\n",
    "# (\"<\"+ b +\">\") is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_PURE_R_2 = return_rank(all_hidden_states_1_PURE_R_2[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\" + b_1_PURE_R_2 + \">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_PURE_R_2['rank_before'] = rank_before_1_PURE_R_2\n",
    "\n",
    "rank_after_2 = return_rank(all_hidden_states_1_PURE_R_2[target_layer_tail][0, :, :], word_embedding, tokenizer(\"<\"+t_1_PURE_R_2+\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_PURE_R_2[\"Out-put layer_\"+str(target_layer_final), \"t\"] = rank_after_2\n",
    "print(\"B PURE_R_2\", res_dict_b_1_PURE_R_2)\n",
    "print(\"Here we check that we actually find the B at layer 5 = rank 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PURE B INTERVENTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e_11'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'rank_before': 0, ('insertion at layer5', 'B'): 0, ('Out-tput layer8', 't'): 0}\n"
     ]
    }
   ],
   "source": [
    "# <e_128><r_3><r_11> b= e_11\n",
    "target_layer_intervention = 5\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft = all_hidden_states_1_PURE  # the one with B instead of r_2\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention+1 ):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_R_TEST = all_hidden_states[0].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_R_TEST_layer_0_1_position= all_hidden_states_1_PURE_R_2[4].clone()   # layer 0\n",
    "    # intervene normal\n",
    "    hidden_states_ctft = all_hidden_states_ctft[0]  # copiamo quelli del run che inseriremo\n",
    "    #hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 1, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 2, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 2, :] =        r_11_id   # \"r_2\" =<r_11> layer 4 ID\n",
    "\n",
    "    #intevento PURE B\n",
    "    #hidden_states_ctft = all_hidden_states_ctft[0]  # copiamo quelli del run che inseriremo\n",
    "    #hidden_states[0, 0, :] = hidden_states_ctft[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    #hidden_states[0, 1, :] = hidden_states_ctft[0, 2, :]   #insereiamo gli hidden state che vogliamo\n",
    "    # Tokenize the word \"r\"  <r_11>\n",
    "    #tokenized_r_2 = tokenizer(\"r_11\")['input_ids'][0]\n",
    "    #hidden_states[0, 2, :] = model.transformer.wte(torch.tensor(tokenized_r_2)).squeeze()\n",
    "    #hidden_states[0, 2, :] = hidden_states_R_TEST[0, 2, :]   # Hidden state di R_2 (normal run)  ma layer 0 fallisce\n",
    "    hidden_states[0, 2, :]= hidden_states_R_TEST_layer_0_1_position[0, 2, :]\n",
    "\n",
    "    rank_middle = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_b[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer = model.transformer.h[i]  # current layer\n",
    "\n",
    "            # attention mechanism \n",
    "            residual = hidden_states       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states = f_layer.ln_1(hidden_states)\n",
    "            attn_output = f_layer.attn(hidden_states)[0] \n",
    "            hidden_states = attn_output + residual\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual = hidden_states\n",
    "            hidden_states = f_layer.ln_2(hidden_states)\n",
    "            feed_forward_hidden_states = f_layer.mlp.c_proj(f_layer.mlp.act(f_layer.mlp.c_fc(hidden_states)))\n",
    "            hidden_states = residual + feed_forward_hidden_states\n",
    "        # final ln\n",
    "        hidden_states = model.transformer.ln_f(hidden_states)\n",
    "    # print(\"--------\")\n",
    "    rank_after = return_rank(hidden_states[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_b[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after\n",
    "\n",
    "print( res_dict_b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interessante vedere che azzecca B e T se metto pure \"B\" (B di layer_0 a layer 5).\n",
    "\n",
    " Ma se metto anche r_2 di layer 0 invece non azzecca piu!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_b= dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OOD case\n",
    " > #OOD ['<e_147><r_4><e_11></a>', '<e_9><r_16><e_11></a>'] \n",
    " \n",
    ">2 nd hop  OOD ['<e_11><r_1><e_141></a>'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------Target : <e_114>      ----------------------------------------------------------\n",
    "\n",
    "ID ['<e_181><r_6><e_114></a>', '<e_84><r_13><e_114></a>'] \n",
    "\n",
    "OOD ['<e_123><r_8><e_114></a>', '<e_14><r_12><e_114></a>'] \n",
    " \n",
    "\n",
    "2- hop  ID ['<e_114><r_5><e_137></a>']\n",
    "2nd hop OOD ['<e_114><r_13><e_117></a>'] \n",
    "\n",
    "gia composto id : \"<e_181><r_6><r_5>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_141\n",
      " B 1_OOD {'rank_before, layer 5 b': 0, 'rank_before, layer 8 search t': 156}\n",
      "as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\n"
     ]
    }
   ],
   "source": [
    "query_change_OOD =\"<e_147><r_4><r_1>\" #\"<e_181><r_6><r_5>\"# \"<e_147><r_4><r_1>\"# \"<e_14><r_12><r_13>\"       # 2 hop ['<e_11><r_1><e_141></a>'] \n",
    "# usato \"<e_147><r_4><r_1>\"\n",
    "h_1_ood,n_r_1_ood,r_1_ood = query_change_OOD.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_ood = atomic_dict[(h_1_ood ,n_r_1_ood)]\n",
    "t_1_ood = atomic_dict[(b_1_ood, r_1_ood)]\n",
    "print(\"b:\",b_1_ood)\n",
    "print(\"tail:\",t_1_ood)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_OOD = tokenizer([query_change_OOD], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_OOD, decoder_attention_mask_1_OOD = decoder_temp_1_OOD[\"input_ids\"], decoder_temp_1_OOD[\"attention_mask\"]\n",
    "decoder_input_ids_1_OOD, decoder_attention_mask_1_OOD = decoder_input_ids_1_OOD.to(device), decoder_attention_mask_1_OOD.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_OOD = model(\n",
    "        input_ids=decoder_input_ids_1_OOD,\n",
    "        attention_mask=decoder_attention_mask_1_OOD,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_OOD = outputs_1_OOD['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_OOD = dict()\n",
    "target_layer_b = 4\n",
    "target_layer_t = 8\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_OOD = return_rank(all_hidden_states_1_OOD[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_ood +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_OOD['rank_before, layer 5 b'] = rank_before_1_OOD\n",
    "\n",
    "# laste layer search for t\n",
    "rank_before_1_OOD_t = return_rank(all_hidden_states_1_OOD[target_layer_t][0, :, :], word_embedding, tokenizer(\"<\"+ t_1_ood +\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_OOD['rank_before, layer 8 search t'] = rank_before_1_OOD_t\n",
    "print(\" B 1_OOD\",res_dict_b_1_OOD)\n",
    "print(\"as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b e_11\n",
      "\n",
      " b_ood e_11\n"
     ]
    }
   ],
   "source": [
    "print(\"b\",b)\n",
    "print(\"\\n b_ood\",b_1_ood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**The following  OOD test is just to extract \"r_2\"** (second r hop, same that is in the Normal run) from an OOD.ood_atomic.\n",
    "What i wanted to test is that by replacing alle the hidden stated of layer 5 of the normal run  with hidden sattes of layer 5 (that comes from OOD but give the same \"b\" and same r_2) the normal run would be able to correct predict. In other words if the model save the B in layer 5 differently if comes from id or OOD. **it doesnt** against my hypothesis!. The test OOD od r_2 was done to make sure the r_2 from the normal run would not save importan information coming from ID. it doesnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_11\n",
      "tail: e_88\n",
      " B 1_id {'rank_before': 0}\n"
     ]
    }
   ],
   "source": [
    "#query = \"<e_140><r_19><r_11>\"      # the inferred chosen (by combining the ID and 2nd hop)\n",
    "h,n_r,r = query.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b = atomic_dict[(h, n_r)]\n",
    "t = atomic_dict[(b, r)]\n",
    "\n",
    "print(\"b:\",b)\n",
    "print(\"tail:\",t)\n",
    "\n",
    "\n",
    "rank_before_1_id = return_rank(all_hidden_states_1_id[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_id['rank_before'] = rank_before_1_id\n",
    "print(\" B 1_id\",res_dict_b_1_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b: e_161\n",
      "tail: e_109\n",
      " B 1_OOD  TEST! {'rank_before, layer 5 b': 0, 'rank_before, layer 8 search t': 2}\n",
      "as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\n"
     ]
    }
   ],
   "source": [
    "#cancella dopo il test\n",
    "query_change_OOD_test =\"<e_141><r_4><r_14>\"\n",
    "# r_11 from ood  \"<e_161><r_11><e_165></a>   and <e_141><r_4><e_161></a>\"\n",
    "\n",
    "#query_change_OOD_test =\"<e_141><r_4><r_11>\" #\"<e_181><r_6><r_5>\"# \"<e_147><r_4><r_1>\"# \"<e_14><r_12><r_13>\"       # 2 hop ['<e_11><r_1><e_141></a>'] \n",
    "# usato \"<e_147><r_4><r_1>\"\n",
    "h_1_ood_test,n_r_1_ood_test,r_1_ood_test = query_change_OOD_test.strip(\"><\").split(\"><\") #\"e_140\",\"r_19\",\"r_11\"             #query.strip(\"><\").split(\"><\")\n",
    "b_1_ood_test = atomic_dict[(h_1_ood_test ,n_r_1_ood_test)]\n",
    "t_1_ood_test = atomic_dict[(b_1_ood_test, r_1_ood_test)]\n",
    "print(\"b:\",b_1_ood_test)\n",
    "print(\"tail:\",t_1_ood_test)\n",
    "\n",
    "\n",
    "# Tokenizing the Query:\n",
    "decoder_temp_1_OOD_test = tokenizer([query_change_OOD_test], return_tensors=\"pt\", padding=True)\n",
    "decoder_input_ids_1_OOD_test, decoder_attention_mask_1_OOD_test = decoder_temp_1_OOD_test[\"input_ids\"], decoder_temp_1_OOD_test[\"attention_mask\"]\n",
    "decoder_input_ids_1_OOD_test, decoder_attention_mask_1_OOD_test = decoder_input_ids_1_OOD_test.to(device), decoder_attention_mask_1_OOD_test.to(device)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "    outputs_1_OOD_test = model(\n",
    "        input_ids=decoder_input_ids_1_OOD_test,\n",
    "        attention_mask=decoder_attention_mask_1_OOD_test,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "# hidden state of the 1_id (which will be inserted in the normal run)\n",
    "all_hidden_states_1_OOD_test= outputs_1_OOD_test['hidden_states']\n",
    "\n",
    "#################### just to quick check everything is right\n",
    "\n",
    "res_dict_b_1_OOD_test = dict()\n",
    "target_layer_b = 4\n",
    "target_layer_t = 8\n",
    "# (\"<\"+ b +\">\")  is just for reconstructing (\"<b>\") from \"b\"\n",
    "rank_before_1_OOD_test = return_rank(all_hidden_states_1_OOD_test[target_layer_b][0, :, :], word_embedding, tokenizer(\"<\"+ b_1_ood_test +\">\")['input_ids'][0])[-2]\n",
    "res_dict_b_1_OOD_test['rank_before, layer 5 b'] = rank_before_1_OOD_test\n",
    "\n",
    "# laste layer search for t\n",
    "rank_before_1_OOD_t_test = return_rank(all_hidden_states_1_OOD_test[target_layer_t][0, :, :], word_embedding, tokenizer(\"<\"+ t_1_ood_test +\">\")['input_ids'][0])[-1]\n",
    "res_dict_b_1_OOD_test['rank_before, layer 8 search t'] = rank_before_1_OOD_t_test\n",
    "print(\" B 1_OOD  TEST!\",res_dict_b_1_OOD_test)\n",
    "print(\"as expected in the case of OOD the B is corrctly found at layer 5 but not T at layer 8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Intervention with OOD insertion**\n",
    "\n",
    "What: Insert in the normal run (ID run) the 5 layer hydden layers coming from a OOD run representing the same Bridge entity and r_2 relation.\n",
    "It has be seen that the model still predict B (as expected as also the OOD predict the B) but also the t. In other words, does not seem that the model store and use information about how he gets to the Bridge. Given one Bridge he is able to secondo hop if the second hop is in ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "layer aggiornato: 4\n",
      "layer aggiornato: 5\n",
      "layer aggiornato: 6\n",
      "layer aggiornato: 7\n",
      "{('insertion at layer4', 'B'): 0, ('Out-tput layer8', 't'): 0}\n"
     ]
    }
   ],
   "source": [
    "res_dict_OOD_intervention= dict()\n",
    "\n",
    "target_layer_intervention = 4\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft_1 = all_hidden_states_1_OOD\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention +1):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states_1 = all_hidden_states[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft_1 = all_hidden_states_ctft_1[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "#r_2  r\n",
    "    r_2_ood = all_hidden_states_1_OOD_test[layer_to_intervene]\n",
    "\n",
    "    # intervene\n",
    "    hidden_states_1[0, 0, :] = hidden_states_ctft_1[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states_1[0, 1, :] = hidden_states_ctft_1[0, 1, :]\n",
    "    #hidden_states_1[0, 2, :] = hidden_states_ctft_1[0, 2, :]  # prova ad inserire r_2 di ood\n",
    "    #hidden_states_1[0, 2, :]= r_11_id\n",
    "    #hidden_states_1[0, 2, :]= r_2_ood[0, 2, :] # this is a r(second hop) coming from another ood (with not even a;r_1 the same. This prove that r_2 does not \n",
    "    # store calculation in the first 5 layers according to paper results.)\n",
    "    \n",
    "\n",
    "    rank_middle_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_OOD_intervention[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle_1\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer_1 = model.transformer.h[i]  # current layer\n",
    "            print(\"layer aggiornato:\",i)\n",
    "            # attention mechanism \n",
    "            residual_1 = hidden_states_1       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states_1 = f_layer_1.ln_1(hidden_states_1)\n",
    "            attn_output_1 = f_layer_1.attn(hidden_states_1)[0] \n",
    "            hidden_states_1 = attn_output_1 + residual_1\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual_1 = hidden_states_1\n",
    "            hidden_states_1 = f_layer_1.ln_2(hidden_states_1)\n",
    "            feed_forward_hidden_states_1 = f_layer_1.mlp.c_proj(f_layer_1.mlp.act(f_layer_1.mlp.c_fc(hidden_states_1)))\n",
    "            hidden_states_1 = residual_1 + feed_forward_hidden_states_1\n",
    "        # final ln\n",
    "        hidden_states_1 = model.transformer.ln_f(hidden_states_1)\n",
    "    # print(\"--------\")\n",
    "    rank_after_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+t+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_OOD_intervention[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "\n",
    "print( res_dict_OOD_intervention)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict_OOD_intervention= dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention ID insertion of OOD normal run (basically means that the first hop is in ID and the second in OOD)\n",
    " Hypothesis: it fails as the model doesn not take care from where it comes. \n",
    " As hypotized the test shows that if in an OOD run we insert the B from an ID run the model still fails. As he still has not seen the second hop in this position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "layer aggiornato: 4\n",
      "layer aggiornato: 5\n",
      "layer aggiornato: 6\n",
      "layer aggiornato: 7\n",
      "{('insertion at layer4', 'B'): 0, ('Out-tput layer8', 't'): 149}\n"
     ]
    }
   ],
   "source": [
    "res_dict_OOD_intervention= dict()\n",
    "\n",
    "target_layer_intervention = 4\n",
    "target_layer_final = 8\n",
    "# juest rename for more standardized structure\n",
    "all_hidden_states_ctft_1 = all_hidden_states\n",
    "\n",
    "# we are analysing  with replacing only specific hidden state once a time\n",
    "for layer_to_intervene in range(target_layer_intervention , target_layer_intervention +1):\n",
    "    print(layer_to_intervene)\n",
    "    hidden_states_1 = all_hidden_states_1_OOD[layer_to_intervene].clone()    # cloniamo gli hidden del normal run\n",
    "    hidden_states_ctft_1 = all_hidden_states_ctft_1[layer_to_intervene]  # copiamo quelli del run che inseriremo\n",
    "#r_2  r\n",
    "    #r_2_ood = all_hidden_states_1_OOD_test[layer_to_intervene]\n",
    "\n",
    "    # intervene\n",
    "    hidden_states_1[0, 0, :] = hidden_states_ctft_1[0, 0, :]   #insereiamo gli hidden state che vogliamo\n",
    "    hidden_states_1[0, 1, :] = hidden_states_ctft_1[0, 1, :]\n",
    "    #hidden_states_1[0, 2, :] = hidden_states_ctft_1[0, 2, :]  # prova ad inserire r_2 di ood\n",
    "    #hidden_states_1[0, 2, :]= r_11_id\n",
    "    #hidden_states_1[0, 2, :]= r_2_ood[0, 2, :] # this is a r(second hop) coming from another ood (with not even a;r_1 the same. This prove that r_2 does not \n",
    "    # store calculation in the first 5 layers according to paper results.)\n",
    "    \n",
    "\n",
    "    rank_middle_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+b+\">\")['input_ids'][0])[-2]\n",
    "    res_dict_OOD_intervention[\"insertion at layer\"+str(layer_to_intervene), \"B\"] = rank_middle_1\n",
    "    #                \n",
    "    with torch.no_grad():\n",
    "        for i in range(layer_to_intervene, target_layer_final):\n",
    "            f_layer_1 = model.transformer.h[i]  # current layer\n",
    "            print(\"layer aggiornato:\",i)\n",
    "            # attention mechanism \n",
    "            residual_1 = hidden_states_1       #store the hidden state in residual\n",
    "            # Apply layer normalization to hidden_states.\n",
    "            hidden_states_1 = f_layer_1.ln_1(hidden_states_1)\n",
    "            attn_output_1 = f_layer_1.attn(hidden_states_1)[0] \n",
    "            hidden_states_1 = attn_output_1 + residual_1\n",
    "            # mlp  = Feed-Forward Network:\n",
    "            residual_1 = hidden_states_1\n",
    "            hidden_states_1 = f_layer_1.ln_2(hidden_states_1)\n",
    "            feed_forward_hidden_states_1 = f_layer_1.mlp.c_proj(f_layer_1.mlp.act(f_layer_1.mlp.c_fc(hidden_states_1)))\n",
    "            hidden_states_1 = residual_1 + feed_forward_hidden_states_1\n",
    "        # final ln\n",
    "        hidden_states_1 = model.transformer.ln_f(hidden_states_1)\n",
    "    # print(\"--------\")\n",
    "    rank_after_1 = return_rank(hidden_states_1[0, :, :], word_embedding, tokenizer(\"<\"+t_1_ood+\">\")['input_ids'][0])[-1]\n",
    "    res_dict_OOD_intervention[\"Out-tput layer\"+str(target_layer_final), \"t\"] = rank_after_1\n",
    "\n",
    "print( res_dict_OOD_intervention)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intervention by putting a pure \"B\". \n",
    "So basically we are inserting in layer 4 the right B and r_2 however as they appear juat in tokenization in layer 1.\n",
    "\n",
    "What wwe are checking is if the learned weights in layer 5 and upwards are able to tract also the \"pure atomics or they just learn to recognise transformations of the pure atomics that well explain why if theay are not able to tract the B_ood in layer 2 as they have no idea how they look like after getting throght tranformations in layer 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 3 -hop sharing loro model\n",
    "\n",
    "MODEL_PATH =  \"/scratch/davide/model_paper/outputs_SMALL_sharing/checkpoint-1500000/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s220331/GROK/Thesis/transformers/src/transformers/generation/utils.py:1547: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_188><r_6>\n",
      "Prediction: <e_188> <r_6> <e_185> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_188><r_6>\"]    # tartget : <e_188><r_6><e_185></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "# giusto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_168><r_19><r_1>\n",
      "Prediction: <e_168> <r_19> <r_1> <e_173> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_168><r_19><r_1>\"]  # target \"<e_168><r_19><r_1><e_106></a>\"   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_150><r_16><r_15>\n",
      "Prediction: <e_150> <r_16> <r_15> <e_142> </a>\n",
      "Input: <e_144><r_9>\n",
      "Prediction: <e_144> <r_9> <e_79> </a>\n",
      "Input: <e_150><r_16><r_15><r_9>\n",
      "Prediction: <e_150> <r_16> <r_15> <r_9> <e_40> <e_51> <e_40> <e_51> <e_40> </a>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "input_texts = [\"<e_150><r_16><r_15>\"]  # target <e_150><r_16><r_15><e_144>   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_144><r_9>\"]  # target <e_144><r_9><e_79></a>   # giusto\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_150><r_16><r_15><r_9>\"]  # target <e_79>   # no\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_150><r_16><r_15><e_144><r_9>\n",
      "Prediction: <e_150> <r_16> <r_15> <e_144> <r_9> <e_40> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_150><r_16><r_15><e_144><r_9>\"]  # target <e_79>   # no\n",
    "\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "In the train **\"outputs_OOD_MODIFIED_composition_SMALL.200.20.18.0/checkpoint-350000/\"** we put some OOD facts in the inferred training (so it become ID):\n",
    "\n",
    "- 1) More precisely for the atomics **<e_0><r_14>** and **<e_1><r_8>** **TWO** 2-hop (inferred facts) were provided each,(to se if now on they would be able to get the 2-hop in general, like being included in a set of atomics that are able to use the lerned rule) :\n",
    ">{\"input_text\": \"<e_0><r_14><r_3>\", \"target_text\": \"<e_0><r_14><r_3><e_100></a>\"}, \n",
    "\n",
    ">{\"input_text\": \"<e_0><r_14><r_6>\", \"target_text\": \"<e_0><r_14><r_6><e_150></a>\"}, \n",
    "----------------------------------------------------------------------------------\n",
    ">{\"input_text\": \"<e_1><r_8><r_6>\", \"target_text\": \"<e_1><r_8><r_6><e_69></a>\"}, \n",
    "\n",
    ">{\"input_text\": \"<e_1><r_8><r_5>\", \"target_text\": \"<e_1><r_8><r_5><e_81></a>\"}, \n",
    "\n",
    "\n",
    "---------------------------------\n",
    "- 2) for the atomic **<e_2><r_6>** and **<e_13><r_8>**only ****ONE** example of 2-hop was provided:\n",
    ">{\"input_text\": \"<e_2><r_6><r_7>\", \"target_text\": \"<e_2><r_6><r_7><e_89></a>\"},\n",
    "\n",
    ">{\"input_text\": \"<e_13><r_8><r_11>\", \"target_text\": \"<e_13><r_8><r_11><e_197></a>\"},\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are testing first if we memorized the inferred fact we trained on in bot the cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 1)** with **TWO** EXAMPLE PROVIDED \n",
    "\n",
    "All the 4 the cases were recall/memorized from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_0><r_14><r_6>\n",
      "Prediction: <e_0> <r_14> <r_6> <e_52> </a>\n",
      "Input: <e_0><r_14><r_3>\n",
      "Prediction: <e_0> <r_14> <r_3> <e_126> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_0><r_14><r_6>\"]\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_0><r_14><r_3>\"]\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_1><r_8><r_6>\n",
      "Prediction: <e_1> <r_8> <r_6> <e_63> </a>\n",
      "Input: <e_1><r_8><r_5>\n",
      "Prediction: <e_1> <r_8> <r_5> <e_151> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_1><r_8><r_6>\"]   # target <e_1><r_8><r_6><e_69></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_1><r_8><r_5>\"]   # target <e_1><r_8><r_5><e_81></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2)** with **ONE** EXAMPLE PROVIDED\n",
    "\n",
    "Really weird but in one case **<e_2><r_6><r_7>**  it recall the learned pattern\n",
    "\n",
    "in the other **<e_13><r_8><r_11>*** it seem to not even have momorized the train example of the inferred (even if the first hop are memorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_2><r_6><r_7>\n",
      "Prediction: <e_2> <r_6> <r_7> <e_93> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_2><r_6><r_7>\"]   # target <e_2><r_6><r_7><e_89></a>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_13><r_8><r_11>\n",
      "Prediction: <e_13> <r_8> <r_11> <e_21> </a>\n",
      "\n",
      "------------------**Let's see the atomic fact**:------------------\n",
      "\n",
      "Input: <e_13><r_8>\n",
      "Prediction: <e_13> <r_8> <e_178> </a>\n",
      "Input: <e_178><r_11>\n",
      "Prediction: <e_178> <r_11> <e_197> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_13><r_8><r_11>\"]    # target <e_13><r_8><r_11><e_197>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "# it fail the inferred seen in the train\n",
    "\n",
    "# Lets see if it memorized the atomic fact in the inferred though\n",
    "print( \"\\n------------------**Let's see the atomic fact**:------------------\\n\")\n",
    "\n",
    "# 1st atomic \n",
    "input_texts = [\"<e_13><r_8>\"]    #<e_13><r_8><e_178> \n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "#2ns atomic\n",
    "input_texts = [\"<e_178><r_11>\"]    #<e_178><r_11><e_197>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let see if the model generalized on atimic seen only 2 times **case 1)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <e_1><r_8><r_2>\n",
      "Prediction: <e_1> <r_8> <r_2> <e_35> </a>\n",
      "Input: <e_1><r_8><r_2>\n",
      "Prediction: <e_1> <r_8> <r_2> <e_28> </a>\n",
      "Input: <e_1><r_8><r_18>\n",
      "Prediction: <e_1> <r_8> <r_18> <e_5> </a>\n"
     ]
    }
   ],
   "source": [
    "input_texts = [\"<e_1><r_8><r_2>\"]   #<e_1><r_8><r_2><e_72>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "input_texts = [\"<e_1><r_8><r_2>\"]  #<e_1><r_8><r_2><e_98>\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "\n",
    "#<e_1><r_8><r_18><e_141\n",
    "input_texts = [\"<e_1><r_8><r_18>\"]  #<e_1><r_8><r_18><e_141\n",
    "predict(model, tokenizer, input_texts, device, max_length=max_length, num_return_sequences=num_return_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiment we can say that adding only 1 or 2 inferred example are not enough to let the model recognise this OOD as ID facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing input: <e_1><r_8><r_2>\n",
      "Input: <e_1><r_8><r_2>\n",
      "Prediction: <e_1> <r_8> <r_2> <e_28> </a>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Print collected last results\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_text, results \u001b[38;5;129;01min\u001b[39;00m all_results\u001b[38;5;241m.\u001b[39mitems():\n",
      "Cell \u001b[0;32mIn[37], line 15\u001b[0m, in \u001b[0;36mrun_predictions\u001b[0;34m(model, tokenizer, device, max_length, num_return_sequences, iterations)\u001b[0m\n\u001b[1;32m     12\u001b[0m outputs \u001b[38;5;241m=\u001b[39m predict(model, tokenizer, [input_text], device, max_length\u001b[38;5;241m=\u001b[39mmax_length, num_return_sequences\u001b[38;5;241m=\u001b[39mnum_return_sequences)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Get the last token/output from each result\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m     16\u001b[0m     last_token \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     17\u001b[0m     last_results\u001b[38;5;241m.\u001b[39mappend(last_token)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "def run_predictions(model, tokenizer, device, max_length, num_return_sequences, iterations=100):\n",
    "    input_texts_list = [\n",
    "        \"<e_1><r_8><r_2>\",   # Example 1\n",
    "        \"<e_1><r_8><r_18>\",  # Example 2\n",
    "    ]\n",
    "\n",
    "    results = {}  # To store results for each input_text\n",
    "    for input_text in input_texts_list:\n",
    "        print(f\"Processing input: {input_text}\")\n",
    "        last_results = []  # To store the last token/output from each iteration\n",
    "        for _ in range(iterations):\n",
    "            outputs = predict(model, tokenizer, [input_text], device, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "            \n",
    "            # Get the last token/output from each result\n",
    "            for output in outputs:\n",
    "                last_token = output.strip().split(\">\")[-1] + \">\"\n",
    "                last_results.append(last_token)\n",
    "\n",
    "        results[input_text] = last_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "all_results = run_predictions(model, tokenizer, device, max_length=10, num_return_sequences=1)\n",
    "\n",
    "# Print collected last results\n",
    "for input_text, results in all_results.items():\n",
    "    print(f\"Input: {input_text}\")\n",
    "    print(f\"Last results: {results}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"<e_0><r_14><r_6>\"  # is in training , it get it correct out\n",
    "#\"<e_0><r_14><r_3><e_100></a>\"   # also in traning\n",
    "# # IT GET IT CORRECTLY\n",
    "#\"<e_2><r_6><r_7><e_89></a>\"  # is in training and it get correct (only e_2 seen)\n",
    "\n",
    "\n",
    "\n",
    "#<e_2><r_6><r_16><e_137></a>   FAIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import GPT2Tokenizer, GPT2Model\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sample array\n",
    "sample_array = np.array([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "dataset = \"/home/s220331/GROK/Thesis/data/composition.2000.200.12.6/\"\n",
    "#\"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "\n",
    "#model_path = \"/dtu-compute/s220331/composition/outputs_BIG_new/checkpoint-1500000/\"\n",
    "\n",
    "model_path = \"/dtu-compute/s220331/composition/outputs_BIG_extream_training/checkpoint-2250000/\"\n",
    "#/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n",
    "\n",
    "target_layer = 8\n",
    "#dataset = \"/home/s220331/GROK/Thesis/data/composition_SMALL.200.20.12.6\"\n",
    "#model_path = \"/scratch/davide/model_paper/outputs_SMALL/checkpoint-1500000/\" # model normal on small dataset wuth chosen checkpoints!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model set up\n",
    "#device = torch.device('cuda:5')\n",
    "device = setup_device()\n",
    "model = GPT2LMHeadModel.from_pretrained(model_path).to(device)\n",
    "word_embedding = model.lm_head.weight.data\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_path, output_hidden_states=True)\n",
    "tokenizer.padding_side = \"left\" \n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha scaling found. Using alpha = 1\n",
      "Alpha scaling found. Using alpha = 1\n",
      "Alpha scaling found. Using alpha = 1\n",
      "Alpha scaling found. Using alpha = 1\n"
     ]
    }
   ],
   "source": [
    "# Create a sample array\n",
    "sample_array = np.array([1, 2, 3, 4, 5])# maybe not needed\n",
    "\n",
    "#here we show that actually hidden states change from layer 0 to layer chosen (now le last but is too obious)\n",
    "# List of inputs\n",
    "inputs_list = [\"<e_1>\", \"<e_2>\", \"<e_3>\", \"<e_4>\"]\n",
    "\n",
    "# Store representations\n",
    "first_layer_reps = []\n",
    "last_layer_reps = []\n",
    "\n",
    "for text in inputs_list:\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    \n",
    "    # Forward pass\n",
    "\n",
    "    with torch.no_grad():\n",
    "    # here the same model but with different input !! \n",
    "        outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        output_hidden_states=True\n",
    "    )\n",
    "\n",
    "\n",
    "    # Extract hidden states\n",
    "    hidden_states = outputs.hidden_states\n",
    "    #print( hidden_states)\n",
    "    token_position = 0  # 'B' is at position 0 in each input\n",
    "    first_layer_reps.append(hidden_states[0][0, token_position].tolist())\n",
    "    last_layer_reps.append(hidden_states[-1][0, token_position].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Combine first and last layer representations\n",
    "all_representations = np.vstack([first_layer_reps, last_layer_reps])\n",
    "\n",
    "# Create labels: \"B_first\", \"B_last\", etc.\n",
    "labels = [f\"{text}_first\" for text in inputs_list] + [f\"{text}_last\" for text in inputs_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 768)\n"
     ]
    }
   ],
   "source": [
    "print( all_representations.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "perplexity = 2# min(30, n_samples - 1)  # Set perplexity to a value less than the number of samples\n",
    "# Perform t-SNE\n",
    "tsne = TSNE(n_components=2,  perplexity=perplexity,random_state=42)\n",
    "reduced_embeddings = tsne.fit_transform(all_representations)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, label in enumerate(labels):\n",
    "    x, y = reduced_embeddings[i]\n",
    "    plt.scatter(x, y, label=label)\n",
    "    plt.text(x + 0.2, y + 0.2, label, fontsize=9)\n",
    "\n",
    "plt.title(\"t-SNE Visualization of Token Representations\")\n",
    "plt.xlabel(\"t-SNE Dimension 1\")\n",
    "plt.ylabel(\"t-SNE Dimension 2\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
